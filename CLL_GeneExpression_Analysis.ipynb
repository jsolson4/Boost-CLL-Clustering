{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\programs\\Anaconda\\envs\\korkin\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "TensorFlow Version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "# this code calls tensorflow 1 compatibility\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import seaborn as sns\n",
    "from BasicAutoencoder import DeepAE as DAE\n",
    "from shrink import l21shrink as SHR  # also changing to l1 to access function\n",
    "import xlrd\n",
    "from RobustDeepAutoencoder import RDAE \n",
    "import numpy.linalg as nplin\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__) \n",
    "# doesn't matter that tf is 2.3 because gen 1 compatibility is specified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terms:\n",
    "\n",
    "Inner iteration:\n",
    "    \n",
    "Outer iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDAE(object):\n",
    "    \"\"\"\n",
    "    @author: Chong Zhou\n",
    "    2.0 version.\n",
    "    complete: 10/17/2016\n",
    "    version changes: move implementation from theano to tensorflow.\n",
    "    3.0\n",
    "    complete: 2/12/2018\n",
    "    changes: delete unused parameter, move shrink function to other file\n",
    "    update: 03/15/2019\n",
    "        update to python3 \n",
    "    Des:\n",
    "        X = L + S\n",
    "        L is a non-linearly low rank matrix and S is a sparse matrix.\n",
    "        argmin ||L - Decoder(Encoder(L))|| + ||S||_1\n",
    "        Use Alternating projection to train model\n",
    "    \"\"\"\n",
    "    def __init__(self, sess, layers_sizes, lambda_=1.0, error = 1.0e-7):\n",
    "        \"\"\"\n",
    "        sess: a Tensorflow tf.Session object\n",
    "        layers_sizes: a list that contain the deep ae layer sizes, including the input layer\n",
    "        lambda_: tuning the weight of l1 penalty of S\n",
    "        error: converge criterior for jump out training iteration\n",
    "        \"\"\"\n",
    "        self.lambda_ = lambda_\n",
    "        self.layers_sizes = layers_sizes\n",
    "        self.error = error\n",
    "        self.errors=[]\n",
    "        \n",
    "        # made changes to deep AE so encoder only takes 1 row as input, will likely break this.. \n",
    "        self.AE = DAE.Deep_Autoencoder( sess = sess, input_dim_list = self.layers_sizes)\n",
    "\n",
    "    def fit(self, X, sess, learning_rate=0.15, inner_iteration = 3,\n",
    "            iteration=3, batch_size=1, verbose=False):\n",
    "        \n",
    "        ## The first layer must be the input layer, so they should have same sizes.\n",
    "        assert X.shape[1] == self.layers_sizes[0]\n",
    "        \n",
    "        ## initialize L, S, mu(shrinkage operator)\n",
    "        ### could try setting array of zeros equal to the number of columns... # changing from X.shape to X.shape[1]\n",
    "        self.L = np.zeros(X.shape[1])\n",
    "        self.S = np.zeros(X.shape[1])\n",
    "\n",
    "        print(\"L shape:\", self.L.shape) # L is 141 x 20; need to treat each row as it's own element. \n",
    "        \n",
    "        print(\"X size is:\", X.size, \"(in case it requires adjusting too)\")\n",
    "        \n",
    "        # X.size: .size is a np function that counts all elements in a matrix (np array) along the specified axis.\n",
    "        # if no axis is specified, counts all elements in the matrix.\n",
    "        mu = (X.size) / (4.0 * nplin.norm(X,1))\n",
    "        print (\"shrink parameter:\", self.lambda_ / mu)\n",
    "        LS0 = self.L + self.S\n",
    "\n",
    "        XFnorm = nplin.norm(X,'fro')\n",
    "        if verbose:\n",
    "            print (\"X shape: \", X.shape)\n",
    "            print (\"L shape: \", self.L.shape)\n",
    "            print (\"S shape: \", self.S.shape)\n",
    "            print (\"mu: \", mu)\n",
    "            print (\"XFnorm: \", XFnorm)\n",
    "\n",
    "        for it in range(iteration):\n",
    "            if verbose:\n",
    "                print (\"Out iteration: \" , it)\n",
    "            ## alternating project, first project to L\n",
    "            self.L = X - self.S\n",
    "            \n",
    "            ## Using L to train the auto-encoder\n",
    "            self.AE.fit(X = self.L, sess = sess,\n",
    "                                    iteration = inner_iteration,\n",
    "                                    learning_rate = learning_rate,\n",
    "                                    batch_size = batch_size,\n",
    "                                    verbose = verbose)\n",
    "            \n",
    "            ## get optmized L\n",
    "            self.L = self.AE.getRecon(X = self.L, sess = sess)\n",
    "            \n",
    "            ## alternating project, now project to S\n",
    "            ### *changed SHR.shrink to l21shrink * ###\n",
    "            ### * should we be using l21 shrink? ### --> check paper... \n",
    "            self.S = SHR.l21shrink(self.lambda_/mu, (X - self.L).reshape(X.size)).reshape(X.shape)\n",
    "\n",
    "            ## break criterion 1: the L and S are close enough to X\n",
    "            c1 = nplin.norm(X - self.L - self.S, 'fro') / XFnorm\n",
    "            \n",
    "            ## break criterion 2: there is no changes for L and S \n",
    "            c2 = np.min([mu,np.sqrt(mu)]) * nplin.norm(LS0 - self.L - self.S) / XFnorm\n",
    "\n",
    "            if verbose:\n",
    "                print (\"Break Criterion 1: the L and S are close enough to X\", c1)\n",
    "                print (\"Break Criterion 2: there is no changes for L and S\", c2)\n",
    "\n",
    "            if c1 < self.error and c2 < self.error :\n",
    "                print (\"early break\")\n",
    "                break\n",
    "                \n",
    "            ## save L + S for c2 check in the next iteration\n",
    "            LS0 = self.L + self.S\n",
    "            \n",
    "        return self.L , self.S\n",
    "    \n",
    "    def transform(self, X, sess):\n",
    "        L = X - self.S\n",
    "        return self.AE.transform(X = L, sess = sess)\n",
    "    \n",
    "    def getRecon(self, X, sess):\n",
    "        return self.AE.getRecon(X, sess = sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a matrix of Sine,  Cosine, & Tangent data to evaluate workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pi_vals = np.linspace(-np.pi, np.pi, 100)\n",
    "sin = np.sin(pi_vals)\n",
    "cos = np.cos(pi_vals)\n",
    "tan = np.tan(pi_vals)\n",
    "\n",
    "X = np.array([])\n",
    "pi_dev = np.std(abs(pi_vals))\n",
    "\n",
    "n = 50\n",
    "corruption_rate = 0.05\n",
    "for i in range(0,n):\n",
    "    # create noise arrays (don't want to be repeating the exact same noise patterns across columns)\n",
    "    noise1 = np.random.normal(0,pi_dev, 100)\n",
    "    noise2 = np.random.normal(0,pi_dev, 100)\n",
    "    noise3 = np.random.normal(0,pi_dev, 100)\n",
    "    \n",
    "    # Combine signal and noise\n",
    "    sin_noise = sin + noise1\n",
    "    cos_noise = cos + noise2\n",
    "    tan_noise = tan + noise3\n",
    "    \n",
    "    # Corrupt \n",
    "    sin_cor = sin + np.random.binomial(1, corruption_rate, 100) * sin_noise\n",
    "    cos_cor = cos + np.random.binomial(1, corruption_rate, 100) * cos_noise\n",
    "    tan_cor = tan + np.random.binomial(1, corruption_rate, 100) * tan_noise\n",
    "    \n",
    "    X = np.append(X, sin_cor)\n",
    "    X = np.append(X, cos_cor)\n",
    "    X = np.append(X, tan_cor)\n",
    "\n",
    "X = np.reshape(X, newshape = (150, 100))\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Example of Corrupted Sine Data')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEICAYAAABCnX+uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd3iUVfbHP3cmM5n0ngAphBBCCoQOIoggVVRQwbUrImLvZdXd/alr24K9LnZXV7FjV0CR3jsJkEASklDSeybJzNzfH+9MmIQESJ/A/TzPPJm3zL3nfSfznTPnnnuukFKiUCgUiu6LrqsNUCgUCkXbUEKuUCgU3Rwl5AqFQtHNUUKuUCgU3Rwl5AqFQtHNUUKuUCgU3Rwl5IoWI4SYI4RY1QHtCiHEe0KIYiHEhvZuvzvQlnsrhHhTCPG39rZJ4fooIXcxhBCZQohqIUSF0+PVrrarkxgLTAYipJQjmzpBCNFTCPGOEOKwEKJcCLFHCPGEEMKrc01tGiHEciHEvA5s/0b7NZcLIY4KIX4QQvgASClvkVI+2QF9zhFCWJ3+HzPsX7hxLWjjfSHEU+1tm0JDCblrcpGU0tvpcUdXG9RJ9AYypZSVTR0UQgQCawEPYLSU0gdN+P2Bvi3pyO796xrtc2uV1Z2EEOJc4BngSvu1JwCfdVL3a6WU3oAfMAmoBjYLIQZ0Uv+KEyGlVA8XegCZwKRmjr0BfOG0/U9gGSCAAOB7IB8otj+PcDp3OfAUsAaoAL4DgoCPgTJgIxDtdL4E7gIOAAXAvwGd/dgcYJXTufHAEqAI2Av86QTX1wv41n5uOnCTff+NgBmw2u17oonXPgXsdNjRTPtn26+l1P737Eb34GlgNZoQxdqv83YgDcgAou373Bq9bp7Tta8GXrH3sQeYaD/2tN1+s/0aXj3Z/bG/B9/a34MNwJPO97bRtT0AfHOCa38feMr+fDyQA9wP5AGHgRucznUHFgAHgaPAm4BHM+3Oacom+/+Y8//j58AR+31ZASTZ988H6oBa+335zr7/YWA/UA6kAJd09eevuz663AD1aPSGnFjIPYF99g/WOWgCG2E/FgTMsp/jY/9QfeP02uVowtkXzatKsbc1CXADPgTeczpfAr8DgUCU/VxnMVtlf+4FZAM32NsZarcrqZlr+AN4HTABg9G+eCY2breZ166jCYF3Oh6I9iV2rd2WK+3bQU734CCQZD9usF/nEvtrPTg1IbcA99pff7lduAIbn3sq9wf4FM2r9gIGALnN3QP7e14NPAGMAdwbHX+fhkJuAf5ut3M6UAUE2I+/iPYFEmj/f/kOeLaZfpt8X4C5wNFG2z5oXxIvAtuass1p32VoX+w6+32sBHp29WewOz663AD1aPSGaEJeAZQ4PW5yOj4SzbPLQvuJ3Vw7g4Fip+3lwF+ctp8DfnLavqjRB08C05y2bwOW2Z/Xf7DtH8CVjfr+D/BYEzZFonmsPk77ngXeb9xuM9eUBtxyguPXAhsa7VsLzHG6B39vdFwC5zltR3NyIT8ECKfjG4BrG597svsD6NE81XinY8+c5B6cjya6Jfb/k+cBvf1YvViiCXl1o+vIA85C+wVXCfR1OjYayGimzybfF2AaUNfMa/zt99GvsW0nuLZtwMzO/sydDg+XjgmewVwspVza1AEp5QYhxAEgFKf4qBDCE3gB7cMVYN/tI4TQSymt9u2jTk1VN7Ht3ai7bKfnWWjeU2N6A6OEECVO+9yA/zZxbi+gSEpZ3qjd4U2c2xSFQM8THO9lb8+ZLCDcaTub42lq34nIlXblceqjqXsDJ74/Ifbnje9zs0gpfwJ+ssf3J6D98tqL9uXQmEIppcVpuwrtPQ5B++W2WQjhOCbQvlhaQjiaU4EQQo8WWrrM3r7Nfk4w2i+W4xBCXAfch/blid224BbaoEANdnY7hBC3o/10PQQ85HTofqA/MEpK6QuMc7ykDd1FOj2PsvfZmGzgDymlv9PDW0p5axPnHgICHVkWTu3mnqI9S4FLGg9SNmq/d6N9jdtvqtyn8z7HQKun074ejc4PF04KSMN707j9E92ffLTwR+P7fFKklDYp5TLgN7SQTEsoQPviTnKyyU9qg5kt4RJgpf35VcBMtFCdH8fE2XGfGtwXIURv4C3gDrTQlz+wi7b9v56xKCHvRtjTvZ4CrkELIzwkhBhsP+yD9uEssWd3PNYOXT4ohAgQQkQCdwOLmjjneyBOCHGtEMJgf4wQQiQ0PlFKmY022PqsEMIkhEhGG+T8+BTteR7wBT6wCwFCiHAhxPP2tn6023KVEMJNCHE5kGi38ZSQUuajCf81Qgi9EGIux2fEhAJ32a/1MrTskR/tx44CMU7nNnt/7L+UvgIeF0J4CiESgeubs00IMVMIcYX9PRFCiJHAuWhjB6eMlNKGJqIvCCFC7W2HCyGmnuy19nvSRwjxClr45gn7IR+gBu1XkydaiMiZxvfFC03c8+3t3kDLv5AUdpSQuybfNcoj/9qeGvcR8E8p5XYpZRrwKPBfIYRjcMkDzdtaB/zcDnYsBjajxS5/AN5pfII9TDIFuALNKz2Clk3j3kybV6J5a4eAr9Fi6UtOxRgpZRFaVkodsF4IUY6WtVMKpEspC4EL0X6dFKL9YrlQSllwKu07cRPwoL2NJLQvH2fWA/3Q7vXTwGx73wAvAbPtk5pePoX7cwdaSOEIWhz5vRPYVWy3LQ0ty+Uj4N9SylP9InTmz2iD3+uEEGVov3b6n+D80UKICnu/y9G+UEdIKXfaj3+IFhbKRRtIb/zl8g6QKIQoEUJ8I6VMQRunWYsm8gPRsoEUrUA0DPUpFBpCCAn0k1Kmd7UtroQQYg7aYObYrrZFoXCgPHKFQqHo5ighVygUim6OCq0oFApFN0d55AqFQtHN6ZIJQcHBwTI6OrorulYoFIpuy+bNmwuklCGN93eJkEdHR7Np06au6FqhUCi6LUKIJmf+qtCKQqFQdHOUkCsUCkU3Rwm5QqFQdHNcpvphXV0dOTk5mM3mrjZF0QpMJhMREREYDIauNkWhOONwGSHPycnBx8eH6OhoGhaWU7g6UkoKCwvJycmhT58+XW2OQnHG4TKhFbPZTFBQkBLxbogQgqCgIPVrSqHoIlxGyAEl4t0Y9d4pFF2HSwm5QqFwXaSULE5fTFVdVVebomiEEvJGPP300yQlJZGcnMzgwYNZv3498+bNIyUlpatNUyi6lAOlB/jr6r/yW/ZvXW2KohEuM9jpCqxdu5bvv/+eLVu24O7uTkFBAbW1tbz99ttdbZpC0eWU1pQ2+KtwHVxOyKMf/qFD28/8xwXNHjt8+DDBwcG4u2uLtwQHa+vAjh8/ngULFjB8+HC8vb25++67+f777/Hw8GDx4sWEhYWRn5/PLbfcwsGDBwF48cUXGTNmTIdei0LRmZTXljf4q3AdVGjFiSlTppCdnU1cXBy33XYbf/zxx3HnVFZWctZZZ7F9+3bGjRvHW2+9BcDdd9/Nvffey8aNG/nyyy+ZN29eZ5uvUHQoZbVlgBJyV8TlPPKuxNvbm82bN7Ny5Up+//13Lr/8cv7xj380OMdoNHLhhRcCMGzYMJYs0ZabXLp0aYM4ellZGeXl5fj4+KBQnA4oj9x1UULeCL1ez/jx4xk/fjwDBw7kgw8+aHDcYDDUp9rp9XosFgsANpuNtWvX4uHh0ek2KxSdgRJy18XlhPxEMeyOZu/eveh0Ovr16wfAtm3b6N27N7t27Trpa6dMmcKrr77Kgw8+WP/awYMHd6i9CkVnUlFXASghd0VUjNyJiooKrr/+ehITE0lOTiYlJYXHH3/8lF778ssvs2nTJpKTk0lMTOTNN9/sWGMVik7GIeCOWLnCdXA5j7wrGTZsGGvWrDlu//Lly+ufV1RU1D+fPXs2s2fPBrQMl0WLFnW4jQpFSyldvJiqTZvo+eSTbWpHDXa6LsojVyhOcypWrKTsx5/a3E59jLxOCbmroYRcoTjNsZaVYausRNbVtakd58FOKWV7mKZoJ5SQKxSnOdbS0gZ/W4tDyG3SRpVF1VtxJZSQKxSnObZ2FHI3nVv9c4Xr0GYhF0JECiF+F0KkCiF2CyHubg/DFApF+9AeHrmUkvK6cnp59QJU5oqr0R4euQW4X0qZAJwF3C6ESGyHdhUKRRuRUmIt17xna0nrhdxsNWOxWejlrQm58shdizYLuZTysJRyi/15OZAKhLe13a5Ar9czePDg+kfj6fmdRXR0NAUFBad8/vfff8+QIUMYNGgQiYmJ/Oc//wHgzTff5MMPP2wXm37++Wf69+9PbGxsl90XRcuxVVaC1Qq0zSN3CHe4d3iDbYVr0K555EKIaGAIsL6JY/OB+QBRUVHt2W274eHhwbZt27rajBZRV1fH/Pnz2bBhAxEREdTU1JCZmQnALbfc0i59WK1Wbr/9dpYsWUJERAQjRoxgxowZJCaqH16ujrMXbi0paXU7DuHu6dWzwbbCNWi3wU4hhDfwJXCPlPK4AJqUcqGUcriUcnhISEh7ddvhlJaW0r9/f/bu3QvAlVdeWV/x8NZbb2X48OEkJSXx2GOP1b8mOjqaRx99lNGjRzN8+HC2bNnC1KlT6du3b/2Mz+XLlzNu3DguueQSEhMTueWWW7DZbMf1/9FHHzFy5EgGDx7MzTffjNXuXTkoLy/HYrEQFBQEgLu7O/379wfg8ccfZ8GCBYBWivfPf/4zI0eOJC4ujpUrVwKaSD/44IOMGDGC5OTkem/emQ0bNhAbG0tMTAxGo5ErrriCxYsXt+m+KjoHW5mTkJe2XcgdoRUVI3ct2sUjF0IY0ET8YynlV21u8KeH4cjONjfTgB4D4fwThwSqq6sb1Ed55JFHuPzyy3n11VeZM2cOd999N8XFxdx0002AtppQYGAgVquViRMnsmPHDpKTkwGIjIxk7dq13HvvvcyZM4fVq1djNptJSkqq95Q3bNhASkoKvXv3Ztq0aXz11Vf1M0UBUlNTWbRoEatXr8ZgMHDbbbfx8ccfc91119WfExgYyIwZM+jduzcTJ07kwgsv5Morr0SnO/472mKxsGHDBn788UeeeOIJli5dyjvvvIOfnx8bN26kpqaGMWPGMGXKFPr06VP/utzcXCIjI+u3IyIiWL/+uB9dChfEOZzSltCKQ7hVjNw1abOQC60U4DtAqpTy+bab1HU0F1qZPHkyn3/+Obfffjvbt2+v3//ZZ5+xcOFCLBYLhw8fJiUlpV7IZ8yYAcDAgQOpqKjAx8cHHx8fTCYTJfafuCNHjiQmJgbQPP1Vq1Y1EPJly5axefNmRowYAWhfNKGhocfZ9/bbb7Nz506WLl3KggULWLJkCe+///5x51166aWAVorAEX759ddf2bFjB1988QWg/QJJS0trIORNTf5Qiy13D6ylds9ZiPo0xNbgEO4AUwAebh5KyF2M9vDIxwDXAjuFEA4VfFRK+WOrWzyJ59zZ2Gw2UlNT8fDwoKioiIiICDIyMliwYAEbN24kICCAOXPmYDab61/jWGVIp9PVP3dsO0rfNhbDxttSSq6//nqeffbZk9o4cOBABg4cyLXXXkufPn2aFHKHHc7ld6WUvPLKK0ydOrXZtiMiIsjOzq7fzsnJoVevXie1SdH1OLxwtx492pS1UlGr1RjyNfriY/RRQu5itEfWyioppZBSJkspB9sfrRdxF+SFF14gISGBTz75hLlz51JXV0dZWRleXl74+flx9OhRfvqp5bUsNmzYQEZGBjabjUWLFjF27NgGxydOnMgXX3xBXl4eAEVFRWRlZTU4p6KiokFRL0fp3VNl6tSpvPHGG9TZp2/v27ePysrKBueMGDGCtLQ0MjIyqK2t5dNPP63/xaFwbaz2GLkxMrJtg532+io+Rh98jb5KyF0MVf3QicYx8mnTpjF37lzefvttNmzYgI+PD+PGjeOpp57iiSeeYMiQISQlJRETE9Oq9TlHjx7Nww8/zM6dO+sHPp1JTEzkqaeeYsqUKdhsNgwGA6+99loDoZZS8q9//Yubb74ZDw8PvLy8mvTGm2PevHlkZmYydOhQpJSEhITwzTffNDjHzc2NV199lalTp2K1Wpk7dy5JSUktvl5F52MrK0MYDLj1CKN6c26r2ymrLcOoM+Kud1ceuQsiuqL4zfDhw+WmTZsa7EtNTSUhIaHTbekqli9fzoIFC/j++++72pR240x7D7sDh//2f5T//ju+08+n9Kuv6b9pY6vaeWLtE/x28Df+uPwPblt6GwXVBXx20WftbK3iZAghNksphzfer2qtKBSnMdayMvR+fuj9/LBVVLS6AmJ5bTm+Rl8A5ZG7IErIu4jx48efVt64wjWxlpai9/VF7++vbZe3ToDLa8vxMWoLifsYfVRNchdDCblCcRpjLSu1e+R2IW/lgKezkPsafamorVA1yV0IJeQKxWmMraQUvZ8vej8/oPWFsxp75FZppdpS3W52KtqGEnKF4jTGWlaGztcPvb9dyFs5Tb+xkIOapu9KKCFXKE5TpMWCraKifrATWj9NvykhVwOeroMScidUGdvmmTt3LqGhoQwYMKBd2lN0PI6BTb3vsdBKa6bp11hrqLXV4mNQQu6qqAlBTqgyts0zZ84c7rjjjgYFuxSujUO09f5+6Hx8QKfD0orBTodgOw92Ou9XdD3KIz8Jqoytxrhx4wgMDGz1fVR0Po4wis7XF6HToff1bZVH7oiFqxi56+KSHvk/N/yTPUV72rXN+MB4/jzyzyc8R5WxbbqMraJ7Yi3ThNYRVtH7+bUqa6WxR65CK66HSwp5V6HK2DZdxlbRvpTVlvHylpe5b9h9eBo8O6wfRwlbh5Dr/P1aNdjpXPkQqI+VKyF3HVxSyE/mOXc2Z3oZW0X7svHwRhbtXcT4yPGMDR978he0EkeqYQOPvKi4xe009sgNeoOqSe5iqBj5KXCml7FVtC8F1VpG0tHKox3aj80RWvHVPGm9n3+rZnY2jpGD5pWrafqug0t65F2FKmPbdBlb0EI/y5cvp6CggIiICJ544gluvPHGFl+zAvKr8wHIq8rr0H6sJaXoPD0RBgMAen//VoVWHJ63t8G7fl9XFs6y1dZS8ccf+EyapFaqciCl7PTHsGHDZGNSUlKO23c68/vvv8sLLrigq81oV86097C1PLb6MTng/QHysdWPdWg/uQ8/IveNn1C/nffKqzKlf7y01dW1qJ0XNr0gB38wWNpstvp91/xwjbzxlxvbzdaWUPzFlzKlf7ys2rmrS/rvSoBNsglNVaEVhaKTKawuBDrYI68uxlp4tD6sAsdi5S2tgOiY1ens/XalR25OSQGgJi2tS/p3RZSQdxGqjO2ZS32MvKoDY+Tf3Y01fX29eAPH6q20ME7uPD3fQZcKeWoqALX707ukf1dExcgVik6mwKwJeYd55FJC1lpslRKjp7F+d2un6ZfXuY6QS5uNmj3aHJOa9P2d3r+rojxyhaITkVJSUF2Am3CjpKaEGmtN+3dSmgOVeVhrdeh0x0rNOhaXaOk0/RN55LKTa5LXHTyIraoKDAZq9ishd6CEXKHoREprSrHYLMQGxAId5JXnbgbAWivQWwvrd7faI29GyLuiJrnZ7o17jxtHXU4OtmpVEx2UkCsUnYojPp4YlAh0UC75oS3YMCKtOvQ1h+p3t7aUbXNCDp1fb8WckgpubvhOmwpSUpuR0an9uypKyJ1QZWybJjs7mwkTJpCQkEBSUhIvvfRSm9s8U3HEx5OCkoCO8si3YPXTvij0ljyo0PLWdT4+IESL662U15bXT8t30FX1Vsx7UnHv2xdTQgIANelqwBPaabBTCPEucCGQJ6XstgWrVRnbpnFzc+O5555j6NChlJeXM2zYMCZPnkxiYmK7tH8mkV+liarDI293IbdZ4dBWbD0uAvLQG22QtRqSLkbo9eh8fVvkkddaazFbzcd55L6Grilla05NxXvMWIxRUeDmpgY87bSXR/4+MK2d2nIpVBlb6NmzJ0OHDgXAx8eHhIQEcnNzW39Tz2AcOeS9fXvj6ebZ/imIBfugtgKrp1b0TOdh1ITcjlYB8dQHOwurNdEvr3Jj+d48Fm/LZdHGg6zYqxXS+nzrPt5eeYD3VmewaONBfthxmD/25bMjp4QjpWYs1uP/p1uLJT8fa34BpoR4hNGIsXdvNeBpp108cinlCiFEdHu0BXDkmWeoSW3fMrbuCfH0ePTRE56jytievIxtZmYmW7duZdSoUad45xXOFFQX4K53x9vgTahnaPsLuWOg0xQOgD4qETKdhLyJafpSSnKKq0k9XEZ6fgXpRys4UFDJoZJqCmpy8eoLb/5+GGPxCiJq8/G1VeKuyyempyQ75UuOmNdRJ/SU6Xwo0QVSoAulSqd58EJAmI+J3kGeRAd5ERPiRXxPXxJ6+BDi496iKfaOgU53e1jFPTa2PhXxTEflkTuhytieuIxtRUUFs2bN4sUXX8TXacag4tQpMBcQ7BGMEIIwr7D2D63kbgF3X6w2rTyuvu9I2PUyVBWBZyB6Pz/qiotZs7+ADRlFbD1Yws7cUooqawm05jOkZhN9q9JJrCzEt7IGr0oL3r9Igis/QmdpSnR32R8NqTZCuRdUegrKvd0o8fYkzzOYdZ6xvOR+FlU6H4K93RkS5c/QqACGRwcwKMIfo1vzQQKz3bkzxccD4N63L+VLlmCrqUHnVGH0TKTThFwIMR+YDxAVFXXCc0/mOXc2qoytFoufNWsWV199df0XgqLlFFRrQg4Q5hnGxiMb27eD3M3Qawg2x3qd8eNg18sc3LaU72uHEpRfR0j2YW75z3LONS9jWOluLiwuJjTfQqhThVurgBIfKPMR5IUaMAtfqgzelBk8qXTzwKwzUmKqxaKrQY8NnbTibq3Bw2rGVFeLV40Zz+o6vKqsRB6qI7m8FCgF9mPR/UJ+AOQHG8g5EMJan2SeM43DYPRgVEwgY2ODOS8+lJgQ7waXZk5NwRARUV92wD22L9hs1GZmYrKHE89UOk3IpZQLgYUAw4cP79xZBG3EUcb2mWeeYe7cuaxdu7bJMrbjx49vUbuOMra9e/dm0aJFzJ8/v8HxiRMnMnPmTO69915CQ0MpKiqivLy8QfXDiooKNm3aVN93a8vYnnfeeRgMBvbt20d4eDheXl7150gpufHGG0lISOC+++5r0TUqGlJQVUC0XzQAoZ6h5FflY5M2dKIdhqvqzHB0F5x9J3W7S5FC8PTeAB7CyK8/fsnn+jTm6lIIrSpj0U9/w6RVLqbYB46G6NkT402ud0/2eMaz3TCUGp0nQkCItzvB3u4Eehnx8zTgZdTj7qbH3U2HEbBKidUmKaq1UmG2UFFjoaCihrzyGooqawHwsZUwsGYb/c17CS87TEhxFdHZdSTvPcR0DlHl/jMHw/VkZIfw044xPOU+mpgQLyYnhHH+wJ4MivCjJnUPpoT4+ss19tVy8WvS05WQd7UBroQqY9t0GdvVq1fz3//+l4EDB9bfn2eeeYbp06e3+JrPdArMBQzvMRzQhNwiLRSZi+q99LYgj+xA2Cx8eiiUo79tZ7SbiQ92ryY/IJI93jsocEthmdVGaCHkB5vYHxzJKu9zSDMk4mnUk9TLl/49fJge4s1doT5EBXoS5ueOu5u+1TbVWKzkFleTVVhFRsHZ7D1SzndHythzpJyaujqS67YwqnwDfQpyicqtJf7AEc7nS44GfElGlBcbMwdz6R8XEOPrzstZWVjOO/bL0dgnGnQ6lYIIiPaYYiuE+AQYDwQDR4HHpJTvNHf+8OHD5aZNmxrsS01NJcE+iHEmsHz5chYsWHBaFc46097DllJrrWXYR8O4bfBt3DroVn47+Bt3/343n174aX1eeWsorKjhyy051K5+ndvMb3NNwQ1cvW0VHtZq7r5Vh86mp3+VAbfKGPaXncNRSx8iAz0Y1SeIkdGBDInyJybEG72u82p7W6w29hwpZ+vBYjZlFbN2fyF5ZVUMrtvCucXLic3NJzrHhptN+8VwONRE4n4zj4+ag3nEGGYPj2Tm4F7kXzwD9379iHjl5U6zvSsRQmyWUg5vvL+9slaubI92FIrTmSJzEQAhHiGAFiMHyKvMa7GQSynZmFnMh2sz+WX3EQKqM7nj6G+sSevF38p+wWyAr4b0ojpnCpaKOHa6eTAmNpg7x4VwblwIkYEdt1boqeCm1zEg3I8B4X5cOzoaKSXpeRWsTBvI73vP5/UDhQQMymVGydcMyDlIXIYZqwAx+EN8zKt58buLeOaHSF7wDCFqrypnq0IrXcT48eNbHFNXdG8c0/MdYZRQTy0DqSUpiDUWK99tP8x7qzNIzS1iVMlSHstcx5AsLa87PUrPBwNHsjJwMgbPQC6KDeP8AT0YFxeCydD6EElHI4SgX5gP/cJ8mDu2D2XmOv7Ym8+PO4fy4Z48ApOyGGX4EbNnJvtNGbgFv8SQCg/SUnoQkX2QK15bwQ3j45iUENapvyxcBZcScimlWrqpm9LZVfC6I45ZnQ4hDzQFohf6U0pBLDfX8cmGg7yzKgNzcS6Tj37HA3tT6VFqo9BbsG6INxOjMnlN/wxR/Yfw/NBwzosPdWnxPhG+JgMXDerFRYN6UW6u49fdR/lyy2C27S8k2n0HUQG/kOabj2/fA0zabWP0+ie4P2suwSG9mHdODLOHRXTba28NLiPkJpOJwsJCgoKClJh3M6SUFBYWYjKZutoUl8ZRZ8Uh5HqdnhDPkBN65CVVtby7KoP31mTSo3wHt+QsYlBqJR61kNLLxPuDRrLLfyyrPO8nJ2wi/7v2OoK9T6+cah+TgVnDIpg1LILsoiq+2NyPRRtHUnI0nxrvL8kO28WUDYc4y/MptiX48cbRa3l5WX/mj4vhqlFReBpdRuY6DJe5woiICHJycsjPz+9qUxStwGQyERER0dVmuDSO0EqQKah+X6hnaJMeeUlVLW+vzOD9NZnElK/l0YyvGbC3Fp2EvbE6+scVUuIxHkO/m1jssQhTah39Zv8dTjMRb0xkoCf3To7jzvNiWZp6lA/XRjP/rDwurvyCCembGbe5lJGGV9mW6MVHRVfx+vKB3DwuhutGR+NhPH09dJcRcoPB0Oy0cIXidKCwuhB/dxXs5DcAACAASURBVH8MekP9vjDPMNJLjqXPVdZYeHdVBgtXHKBv+Vr+ekATcKsOtieY+Kz3TNK8zuLdnl9xY94ibuw9BFZ/BANmQ0hcV1xWl+Cm1zFtQE+mDehJyqEy3l4VxQN+hxjR/3cuyfiZkTsqGbr7LbYnePBByTW8tTKZ2yf05apRUW1Kp3RVXEbIFYrTnfyq/OPyxUM9Q1lzaA21Fhv/W5/FK7+lE1y8hUcy/0dyai1WPWwZ4MF/o64k328Qc86O5oPR0QR4TIZF5bD8GRA6GPdgF11V15PYy5fn/zSYh6bG8/bKaP5v/UTi+67h8ozFDN1VTXLqW2xN8uLdkut5Z1USD0zpz4xBvdCdRoOiSsgVik6iwFxAkEdQg32hHqFU1lUy6cWfqTuSxZ3ZbzNkVxU6qQn4B1FXU+yfzE3nxHDd6N54uTt9ZC99Cz65AsKSzihvvDl6+Jn464WJ3DYhlndX9eGpNWPo32cll+//lpHbK0lOfZ0NyQH8X8GtLFwRzV8vSODs2LZPxHIFlJArFJ1EYXUhg0OPzRzemVPKp2vLcNNLZu5+knO3lOBRAzvjDXzc9zIO+o7ilnP7Hi/gDty9Yc7pM6GsvQj0MvLA1P7cOLYP/1nRm8fWjGVwzG/8ae+PjN9UzGCvZ1gxOILrDt3G+MRIHp0ef1xdl+6GEnKFohNwLLoc4hFCXrmZBb/s5fNNB5lTuIpzd1oJKykhrbeOzxKmscV3MjeO7cNN42LwNRlO3riiSQK8jDx8fjw3ju3Dq79F8KDneKb2/ZKLdq9lxuochoc8yneVI5iy9wrmnB3N3ZP64dNN73e7TNFvKU1N0VcoTmfKa8s5+5OzOSfoBlZsTGJU/jru2fk5bvlWigLhqyHD+MbvKq4YEck9k+II8Tm9s0+6gqzCShb8uo/vtmVzQ8nbTNyaRlAZ7Omj572E2RwKHMvD58dz6ZBwl42fNzdFXwm5QtEJfLNrC3/bfD1eB87nH5tWEXagCGGQrEsawNOR1zAuMYJHpscTG+pz8sYUbWLrwWKe/D6FfZmZ3HboNUZvL0Zng43JPrwccSdxMX156pIBxPdwvZr7SsgVii6gsKKGZ37cw7epv3N+6VvMX2ZFXwtHYoJ4tP9NeEf04W8XJjIuLqSrTT2jkFLy/Y7DPPtjKt4Fm7lp338ZkGah0Bd+GprEp4FzmTsmmnsmxTU9PtFFKCFXKDoRKSWfb8rhmZ9SGVD0C1dv/4nowxJziI7XBlzG+rDR3Dc5jmvO6o1B315L5ypaSnWtlTeWp/PmigNMLfmMS7auo2ch7O2j553EyykMPpu/zxzApMSwrjYVUEKuUHQaB/IreOSrnaSmp3PPwZcYsbOSanf4bWhv3gy+nVnDonj4/HgVB3chDhZW8cR3u1mVksmdR15izNZChIRVQwN5qce9TBzYhydmJhHm27VlKJSQKxQdTJ3VxsIVB3hpWRozij5i5uYtBJfCtngjr8fOwyM8macvGciI6MCuNlXRDEtSjvL4t7vxzVvP/NSPic+wcigEPhlyHusDZvDI9ASuGBHZZYOhSsgVig5kV24pD36xg4rsbdyR9hbJe+vIC4Avh57Fr4F/4u6Jccw7p48Ko3QDqmotvLQsjbdXpHN10bucv3kPvpWwaaAnL/S+i/h+cfzj0mSig71O3lg7o4RcoegAzHVWXlqWxsI/0riu6C2mbUzD0wzrB/nwYuTdDI3vx9MXD+jyhRwULWf3oVIe/Wonh7NSuXv/awxNqaHAD74ZPowfAq/mgSn9uWFMn06tf66EXKFoZ7YcLObBz7fDoc3ckfoe8QesZIfBh0OmkxI0jf+7MJGZg3upsszdGKtN8sGaTP79y14mFS9i9uZ1hBbDtgQjL8TeQXifRP49O7nT0kaVkCsU7YS5zsoLS/bx1oo05hW8zpSNWRissHJoEC/1uIfpQ/vy2EVJBHoZu9pURTuRXVTFo1/vZNvedO7NeoFROyop9YJvRwzkq6AbuH9yHPPOielw71wJuULRDmw9WMwDn29Hf2gDt+/+gLhMG5m9BO8MupSckAk8fckAJia4Rqqaon2RUvLlllz+/t1uRhZ9y1Wbf6NnIWyPN/BC7B30ikni37MHERvacXVblJArFG2gxmLlpaVpvLl8H/MK32DKhkzcrPDHsFBe6XEPs0b05S8XJqjaKGcAR8vM/OXrXazZnc592c9z1rZyyrxg8chBfBN4PQ9O7c/cMX06JLNFCblC0Up25ZZy/2fbseRs4o6Ud4nPsJLZS/D2oEs5HDqBZ2clc66amXlGIaXk2+2H+L/Fuxle+C1Xb15Gz0LYmmDkhdi76BObyILZg4gKat9B7uaE3HXmnioULobFauON5ft5aVka1xT8h+kb9+FeC0tGBvNyz/uYPbIv71+Q0G0r5ilajxCCmYPDGR0TxKNfB3KHaSz3H3yOs7ZX8GLOAj6vHsG03Kv4ywUJXDUyqsMHvJVHrlA0QXpeBfd/to2CzO3cu/dNktIsZIfBO0NnkhkyiX/MSmZC/9CuNlPhAkgp+XprLo99u5sxhV9z5aY/CC2GjQM9WBB9L4MT+vOvWcn08Gv7rFAVWlEoTgGbTfL+mkz++fMeLi56n0vW78CrGlYNDeD5Xvdx0bBYHrsoCT9P5YUrGnK4tJo/f7mTbal7eSDzBUbsrCYvAD4ZPo41QZfy5MUDmDGobemoHSrkQohpwEuAHnhbSvmPE53fGiGXUnLXp9sYGR3ANWf1Vrm5inYnp7iKBz/fwb60FO5Pf4khqbUcDoIPhk9lV/AFPH3JQKYN6NHVZipcGCkln2zI5ukfUphc+AmzN24goBzWDfJmQdQDnDeoH09ePKDVqakdJuRCCD2wD5gM5AAbgSullCnNvaY1Qv7Zpmz+/tkK3KSFgfHx/Gt2Mj39PNpiukIB2CsVbs7h79+lMKHwU/60cR2BZbB+kBcLoh7gnIGxPH3JQIK9VZErxalxsLCKB77YTkZ6CvelvczgPbUcCoH3h53PnpDp/HPWQM6Lb3maakcK+WjgcSnlVPv2IwBSymebe01LhTy7qIrzX1rJA6mPEnOwik9GnMOqoFk8OXOAmjmnaBP55TU88tVO1u3eywNZzzNiexWF/vDpiDGsDLqMJ2YkccmQcPU/pmgxNpvk3dUZ/OuXvcwueIeZG3bjUQP/GzeQrwJvYMVDE1ocN+/IrJVwINtpOwcY1YQB84H5AFFRUS3qID2/AoAtIcnEZq7jjqUrGT5oK49W3c8vu/vx1MUDCFLekqKF/LTzMH/5ZheD8r/j5c1L6FkIWxLdea7vPST2T+CX2cn08le/+hStQ6cTzDsnhnPjQrjvMx9WeW/h5gPv8rvXJO6dHNcug58O2sMjvwyYKqWcZ9++Fhgppbyzude0JrSSXVTFg19sJy0ttT5+eSgYPhg2jZSQ6Tx7aTKTXaT4u8K1Ka2q4/HvdvPj5jTuy32Os7eWUuEJX48czLdB1/Ho9ASuGdXbZddtVHQ/6qw2Xv0tnVd/T2dwpD+f3Ty6VdP5O9IjzwEinbYjgEPt0G4DIgM9+d+8s3hvTQ+e+Lknl/Z4l5nrd/Hgkp9ZNXQ9t71/HzNH9OP/LkpUs+sUzbJ8bx5//nIH0flLeWXLYiKPwq44N56Lu50efQby458GERPScVOsFWcmBr2OeyfHcV58KP6ehnavydIeHrkb2mDnRCAXbbDzKinl7uZe09b0w/S8cu77bDuFmdu5d8+bJKVbONhD8PaQS8gJPY9/zkpWayAqGlBRY+HpH1L5fH06dx1+nnM3F1BjhB9HxPFxyM3cMymOm8fF4KbqhStcmI5OP5wOvIiWfviulPLpE53fHnnkdfZZdy8vS+O6gjeYviEdgwWWDwvlpR73cOVZsTwyPQFvF1o4VdE1rNlfwENf7CD46Armb/+MPrmSPX30vJw4D/fIoTz/p8Ek9nK9FdMVisacthOCduWWct9n27DmbOKu3e8Sl2kjI1zw5qA/URQ2jn/NSubs2OB26UvRvaissfCvn/fw3zVp3JH3CudtOoxVwJKRUSwMvp1bxsdx96R+uLvpu9pUheKUOG2FHLTKdC8sSWPhH/uYX/Aqkzdko5Pw+7AevBp2F1eNjuXh85V3fiaxdn8hD325Hf+jq7l5xyf0zZakR+l4fcA11PQazYI/DWJoVEBXm6lQtIjTWsgdbM7SakWbDq3ltl0fEXvQxoEIwX+S/0Rh6DievXSgip2f5lTUWPjnT3v4eG0at+e9woTNhwFYNjyc10PvYu7YWB6Y0h8Po/LCFd2PM0LIAaprrSz4dS/vrkrn1vxXmLQxB52E5cPCeDnsbi4b0ZdHL0jAz0Nltpxu/LEvn0e/2klQ3grm7/iMvjmS/ZGCNwdcTVnPs/n37GRGxQR1tZkKRas5Y4TcwYaMIh76Yjseh9dx6+6P6JelreTy7qBLyAqewN9nDlB1M04TiitreeqHVBZvPsCdR17g3C352AQsGxHOa8F3MWdMXx6a1h9PowqtKbo3Z5yQg+adP/frXt5Zlc78gteZvDELgwVWDwngpV73cl5yDE/MSCLUt/1mWCk6D0dx/79/l0K/wqXM2f4dvQ9L9kXreDPxGqp6nsW/ZikvXHH6cEYKuYPNWcU89MV2OLSF2/a+S2K6ldwQ+GTIRDYEXMRD58dz9cgoNZOvG5FdVMXfFu9iQ+oB7s15gbO2lWE2wq8j+vBO0C3ceE4s901WsXDF6cUZLeSgrXz+2u/pvLF8P1cWvcX0jXvwrYLNAzx4KfoOovr05+mLB6p8Yhen1mLj7VUHeHlZGpOLP2PWlnWEFcHOOAOvxs3DFD6If80exOBI/642VaFod854IXeQeriMP3+5gyNZqdx14DWG7K6h1Ad+GpbAx/5zmDMmlnsn91PLd7kg6w4U8n+Ld1Gdu4Pb099m0J5aCn3h2+GD+SbgOu48L5abz+2L0U3NzlScnighd8Jqk3ywJpPnft3LOcVfc9nWFfQqgH3ROt5JvIwjQWN5dHqCKpHrIhwtM/PMj6l8tzWTmwteZ8KWHDxqYGOyFy9G3k18bCzPXjqQvqpGiuI0Rwl5Exwqqeaxb3ezYlcGtx95mbHbCtDbYN0gP14Nv5P4mD48PiOJpF5+XW3qGUmNxcp7qzN59bd0RhR/zxU7lhF1RJLZS/DfgReQGjSZR6YncNmwCPWFqzgjUEJ+ApamHOWxb3fjnbeRm/Z9RFK6hUJf+GVoPB/738CfRkRz35Q4Qn1UdktnIKVkaWoeT/2QQlnJfmZV/IdLfqmg3BN+GxbNwsBbmT28N49OT2j1klkKRXekI8vYdnsmJYYxJjaYV37rxaMeyUzv/Skztm3gquV7GBX5MIvM05iwfQq3TYjlxrF9MBlUJkRHsTOnlKd/TGHzgUOMCvqQ/X3T8V0iqTEK7pp4D0ERCXwxM4nh0YFdbapC4TIoj7wRGQWVPPV9CitSsrg971XGbjuKRw1sjzfyTsz1VAYN4r7JcVw6NFyVPG1HsouqeH7JPr7ems1w328pD1nLIaMgodKNGV+FEVZmJveF97jmrN7qvivOWFRopYX8viePJ39IofpwKrdkvcXQ3dVY9LBpoC9vht9MYM++3D8ljqlJPVR8tg3klZl59fd0PtlwkPEV36EPWcXqSIiolZjyxrG94nze3fY+Ef4mYj/5uKvNVSi6FBVaaSET4kMZ2y+Yj9b15vmlfYmNWMFVaYsZu6WM5D3/Zt3AUB44Mp9XIqK4d1IcExNClaC3gPzyGt5aeYAP12YyvHwp/977C/0zrGSHQNlFA1lfdCVn9+vFjxckYLxpIcbg8K42WaFwWZSQnwCDXscNY/pwyZBwXl8eySNeYzg35lsuTvmDKevzGOH9FGsH9uTOnJvpG9mL28fHMjWph5ohegLyyswsXHGAj9ZnMajiD55M/4HENAtmdyjwN+BX6kaR8Q7em5tQX6lyX1ExHkOGdrHlCoXrokIrLSC3pJoXluzjyy05zCxfxLTdm+h9WFLkA+uTevBe6DzCekQwf1wMMwf3UgsWOHEgv4KFKw7w1ZZcBlWu4PL935OQZqHWAFuTvHgr4kYuzklnxrYf6bd9O27uWjaKtNnYMzCZoJvmEXrPPV18FQpF16JCK+1AuL8HCy4bxC3nxvDC0p7c4pXDZeWfct6ebZy/7ghnez7F5qRAnjt0Pf/+JYbrR/fmqlG9z9gUOSkla/YX8t7qTJbtOUpS+Vr+mv4rIzLLqTbCusHevB9xHeaABO48L5bzD6ylYNuPyNISCA0FwFZWBlYrbgFqEQiFojmUkLeC2FAfXrtqKHdMiOWlpeHc6pPLjIqvmbJvPedtLGK08QV29vfgi6JLePm34Vw4sCfXju7N4Ej/MyKOXmauY/G2Q3y0Nou0w4WcU/Izz6dtIP6wmXKTYO8wG6URfVnodx+3ntuXK0ZGYTLoKSvfB4C1sBCDXcgtxcUA6JWQKxTNooS8DST09OXNa4eRdjSO15dHcZdvLucmLuH8jN8Yurua4bv+x77oRawpSmbWlsuI6xnEZcMjuXhwL4K83bva/HbFZpNsyirm803ZfL/jMJ51RVxW+C5/3XaI4HLJUT8dC0cl82PopWz3uoP90VP54+oJDXLy3YK1tVUthUX1+6zFJQDoA1TeuELRHErI24F+YT68cPlg7pscx7uro3l84zR6x25l1uGvGbi3nLkZW7nIfyu7YwP47OBM/vHTQM6NC+WiQT2ZlBCGVzddS1RKyb6jFXy3/RDfbMvlUHElY3S7WKD/jQn6zWSsCiMnRMeTQ89jnf9kEiMCeW5sJKbFtSTFREKjiVVugZpYWwsL6vdZizVRVx65QtE83VNBXJTIQE8euyiJeybF8emGfnywfhSFkXlcWfwRQzMOMH5TMePE+xyI1LHraCRP75rFn00RnBsXwqSEMM6LD3V5T91qk+zIKWFp6lF+2nmEAwXlDLFt5xrDLi52X0cPUUyR9GZR2VjOkmnsG+CD/5gbWDSmD8N7ByCqCrWGTMeXmdU36ZFroRW3QCXkCkVzKCHvAPw8DNx8bl9uOieGP/bl8991fXkvOI8ByRu56MhPJKSXcfHBLC7QP8/+KD17D4fzyvYLeMjQl+QIf8bGBjEmNpihUQFdXg5ASkl2UTXrMgpZnV7Ain35lFRVE+exiQjf1fj1PMITCyVl51ayMyiWv1vHsMw2lIm1OziLNCKjPbjz6mHHGjSXan9Nxxci03l5IYxGLE4euaVIxcgVipOhhLwD0ekEE+JDmRAfytEyM19tieeTzeM5EFnGlKqfGHNkPf0yqonPOMhFvEF2T0FWL1+27UnmbY/J2AxeJPbyY2iUP4Mi/Eno6UtMiBeGDpyiXlpVx+7DpezMKWVHTimbs4o5UmamT10aQ+RKkvrkcjC8nENuOo5KydiDbhisdazOG8C7gXcyeUAYbwwNp9cve5C/g6d/o/RWsxbzbkrIhRDog4KwNvLIhYcHOg+PDrtmhaK70yYhF0JcBjwOJAAjpZTdLzm8kwjzNXHr+L7ccm4Muw+V8d2OfizcfpjcmAomVC9ldMF6+uSUMXZzKeNYyU3GleT20HEk2Ju03TE87zmag259Mep19An2oneQJ9HBXoT7exDq406orzsBnka8TW74uBswGXT1GTJSSmqtNsx1NipqLBRX1lJSVcfRMjOHSqo5VFpNRkEl6XmVFFTU4G6rYlTNGpIqdjOmOI9eh2sI0xxj/n6dIFJ406sijpSySRzJKwLeYqCtjo1/nYSvfUGOXQsPUuYFXpgb3ogTeOQAbkFBWAoL67etRUXoA9RqPwrFiWirR74LuBT4TzvYckYghGBAuB8Dwv14eFo8uw+VsSQlnm9SLiMlqoxwSyaTyn+lX0EWPfNqOHtrGWPlNm5gGyVekB+sQ2fyo9gUyn6vcJZ6hLPfvSeHDMEgjvfU9TqBTUoaz/tyt1URbTlATN1+epkPMb6qkFnlFQSUWAgpAqNFO6/SHXJ66sjp4c2w1DLYey07+wzlnH4hPJ4QytnZ2yheBaEFpfUiDmA7mMPhQIitqWzY8UmEXB8UiDXfKbRSUoybylhRKE5Im4RcSpkKnBG50R2Bs6jfOzmOvHIza/cXsiptLG8eKCSnuJog61HOqV5OTFkmYaUl+JTUEZVbRF9LMcPZW9+WRS+pMAlqjFBrBIubQAqQgADcrKC3SIx14FUNnjXH21PkA4UBOrYmmsj268k278FsNQ7DYDBxnm8dw1L/zJ/HRDDgxsn1FQiL960CwDO/HFt1dX0IRJd7lMNRgiE15Q07OalHHkzNnmPXZS0uUfFxheIkdFqMXAgxH5gPEBUV1VndditCfUzMHBzOzMFagai8cjNbskrYln02mw+XkXq4jKpeD1JbeDZROckkV6bT23yUsJpict0z8DVDQLXAWGdDb5UICToJUkCtQWAx6bAYBNXuBqqNRircvcgzBXPQ2Ju9hkSK9CEY9TpiQrxI6uXHjAg/Hg33Y0C4L27VVex7FyLdLA3KyFpLNGEWEmoOHMAjKQlrRQX64nKODNLhXV0GNhvo7K9xCLl704tcuwUFYikqQkqJEAJrURHG3r077qYrFKcBJxVyIcRSoEcTh/4ipVx8qh1JKRcCC0GrtXLKFp7BhPqYmDagB9MGHLv9o//nwejBIYybeCGZhZUcKathZ7mZjfJ2jNUjkYUzKTNbqLXYGrRl0AtMbno8jHoCvYz4exoI8nInPMCDqX4m5gZ4EhvqTWSAR5P1vqW3N7i5YS0pabDfWlpa/7x2/348kpKozcwC4FAgeNtsUFMKHnav2lwKQg9GryavWR8UBHV12MrK0Pv5YS0uVqmHCsVJOKmQSykndYYhilPD080DX0+4eEjDsq5D/lvHVSP7cu+wyfX7bDaJze7Z6ttYkVEIoQlrE0Je6WvEVFFLTfp+AGozMwHIC9ThUSGhuqShkJv8oJlwnFtQEKDlkgsPD2yVlSq0olCcBJV+2M1wd3On2lLdYJ/FZsFis2Bya7imqE4n0NF+4xfNCbnZ10S5SeK3/5iQSwHlwSZEBcdSDuGYkDeDQ8ithQXovDy1ftVgp0JxQtqUkCyEuEQIkQOMBn4QQvzSPmYpmsPkZqLG2nCk0rHtoe/YXGu9v3+DUAqAtbQEq7eJ3GAdNelpANRmZVEZ6ImHhz18Un3qQq538sitRY7p+Sr9UKE4EW0Scinl11LKCCmlu5QyTEo5tb0MUzSNSW/CbGmYm+3Ydnfr2On9en//4zxyW2kpNh8vsgKt1GXnYDObqc3MpDjEhJfBLuSt8MgthQVO0/OVR65QnAi1im03w+RmwmxtJOT2bZPe1NRL2o2mhNxaUgq+3mQF28BmozYjg9qsLAqCDXgb7ZkpLfHI/f1BCKyFRaqErUJxiigh72a4692b9cgbx8jbm8ZCLqXEWlqKzs+XnGAtFl+1cRO2sjKOBOrwcbcLttkpHHMSIRdubugDArAUFmJ11FlRHrlCcUKUkHczPNw8jouRd5pH7ueHrKnBVq0NtkqzGVlbi97Pj8MBgF5H+bJlAOQE2PB29wedoVFopeyEQg5aLrm1qFALrQiB3rfpnHOFQqGhhLyb4a4/PmulMz1yOJY77vhr9A/UZpJG9KTKvhZrlm8d3kZvTbQdoRVrHdRVNlnCtkE/gUFYCgqxFBeh9/dH6NXapwrFiVBC3s1oMmvFUlN/rCOpF3J7eMUh5O4BWh3xuqgwsFrBzY1M70q8Dd7g4X/MIzeX2S/iZB55EJaiQjU9X6E4RZSQdzOaylqptlbXH+tIjhNy+/R8U6Am5NUR2l9DRDi1WO0euf8xj/wEJWwb9BMUhLWg0F75UAm5QnEylJB3M5rKWnF45J2RfgjOHrn21ysoDIDyXppAi8heAE145CcumOXALSgIW2UldUeOqOn5CsUpoIS8m+Gud6+fyenAIeydMSEIjg+t+AT3BKCop7e2P0KrDXO8R35qQq4P0rJU6rKz0fsrIVcoToYS8m6Gh5sm1s5xcsfgZ8d75JoAO0IqNruQewf2QCd05IcaMQ1KpnZ4IgA+Bp9mPPITZ6G4BWkhGqRUqYcKxSmghLyb4a7XxNo5c8Uh6h0dI9e5uyM8PBp45MJgQOfpibfBm3JZTZ9Fiygf0hdw8sjNpSBlC0Irx8RbTc9XKE6OEvJuhiMzxdkj76z0Q2g4KchaUorO3w8hBD5GH8prtUUkKuu0VYHqY+TSBjXlLQitBNc/V9PzFYqTo4S8m+Hwup0zV8xWM0adEV0TS721Nw2EvLQUvZ8myt4Gb8rrNCF3CHp9Hjlo4RVzqbYcndH7hH009MhVjFyhOBlKyLsZDq/bOXPFbDF3ijcOWpy8oZBroQ9nj7yirgKwe+SOyT/VJSetRe5A5+GBzlOVsFUoThUl5N0MR4y8gUduMXd4fNyB3s+/wczOeo/c6E1FrSbgjr/1oRU45pGfJKxS34+9CqKbipErFCdFCXk3oz5rxeIUI7d2pUeuCbOv0bfeE6+oq8DDzQO9Tt+0R34KOMrZqtCKQnFylJB3M+qzVqzHslY6N7SieeTSZjsuRl5Wq03Br6ir0FIPoU0euTCZ6kMsCoWiedRSb92M+qwVJ4+8xlrTeaEVf3+w2bAWFSGrqupzy72N3lTWVWKTNspry7WBTjjeIw+OPaV+TAkJWAryO+ISFIrTDuWRdzPqs1a6bLBTE+barCxt2ym0YpM2quqqqKit0OLjAO4+IPSaiNecvIStg5A7bqfPokXtfwEKxWmIEvJuRn3WSqP0Q0fIpaM5JuQHtW2n0ApoYZXKuspjHrkQmnjXh1bU4KVC0d4oIe9m1GetdJVHbhduh0eus2/7GLWYeHltOeV15cc8ctDi5JUFUFtxyh65QqE4dZSQdzOaipGbLeb6bJaO5vjQirbt8MDLa8upqK2oF3ZAE++SpmF9cAAACgVJREFUg8eeKxSKdkUJeTdDJ3QYdcaGWStdElqxC7l9sNORpVJRV0FFXQVeBq9jLzL5Q0mW/bkScoWivVFC3g0xuZmO88g7LbTi6wtCUNdosNPhgRebi6m2VB+LkYMWWqkqtBuvhFyhaG+UkHdDTPpji0tIKTs1/VDo9eh9fbFVVYFej85bE2yHcB+pPAIc89A1g50GON3VQsoKRXvTJiEXQvxbCLFHCLFDCPG1EEKlJHQCJrdjy71ZbBas0tppHjmAzh5O0fv6Iux1Uxwe+eHKwwDHe+QOlEeuULQ7bfXIlwADpJTJwD7gkbabpDgZ7m7u9ULeWet1OuOIkzvCKqBl0xh1xnqPvEHWikkJuULRkbRJyKWUv0opHWuOrQMi2m6S4mR46D3q65E7YuWd6ZE3JeSgeeHKI1coOp/2jJHPBX5q7qAQYr4QYpMQYlN+vpp63Rbc3dzrVwjqzEUlHLjZhdwRYnHga/StF/ImY+SnUItcoVC0nJMKuRBiqRBiVxOPmU7n/AWwAB83146UcqGUcriUcnhISEj7WH+GYtKb6j1yx6BnZ6Ufwgk8coN3/RdMw/TD/2/vbkPkOsswjv+vmd3MtImNTTWmTYJNIGlTxaS6SH3BtwRNa2kEv6SlmA+CCIrVCtoSUESEgiIKvhEatWhtP9RSQwRprYKfjEYNJZrERmvbaDQrkkR0d5tJbj+cc9Kz232LM7NnnznXD5adOZvsPje7uXLvfZ5zJv9zrSug4fPrZr02502zImLbbB+XtAu4FdgaEdGrhdnMyic7i/cLdUEQlIN88rnt8kVA045WPFYx64uu7n4oaTvwaeDtEfHf3izJ5lLeflhFR15clj/djLww+cpOB7lZP3X7e+7XgJcBT0g6JOlbPViTzaG8a6XKGfnUIC/Ce7gxPPk/FnfkZn3VVUceEfO7ubT11HQz8kq2H0452Vmc4Jy09RCgtRyQg9ysT3zmKUHTzcgXsiNfsn49zeXLaW3cOOl4MVpZNnVnSqORhbhvYWvWF36FoAS1m2060eHchXOVdOTDq1ax8cAvX3K8GK28pCMH2H4frLy+30szqyUHeYLKt7Kt4oKgmRRBPulEZ2HL7Qu8GrP68GglQeWXe7vYkS+GIM9n5JP2kJtZ3znIE9Qayl8lqDPOWGcMIZY0llS8qhdn49N25GbWNw7yBJVft3OiM0F7qH3xLoRVmnVGbmZ94yBPUDFamTg/wfj58QU90TmbIsg9WjFbWA7yBBUd+VhnjPHO+MVRS9WWL1lOQw1WtFdUvRSzWvGulQQt1o582ZJl7H33XjZdtanqpZjVioM8QVNn5At5w6y5jKwaqXoJZrXj0UqCivuYjJ8fZ+z82ILeMMvMFh8HeYKKDny8M854Z3xR7CE3s+o4yBNU7sgnzk8smhm5mVXDQZ6g8ozcHbmZOcgTVHTkxa4Vz8jN6s1BnqCGGrSaLXfkZgY4yJPVarYuzsgX0/ZDM1t4DvJEtYfajHXGGOt4+6FZ3TnIE9Vutjk7cTZ77NGKWa05yBPVHmpzeuJ09tjbD81qzUGeqHazzZmJM9ljd+RmteYgT9SkjtxBblZrDvJEtZqtFztyj1bMas1Bnqj2UJtOdC4+NrP66irIJX1e0lOSDkl6XNI1vVqYza7chXv7oVm9dduRfzEiXhcRW4D9wGd6sCabh3IX7guCzOqtqyCPiLOlp0uB6G45Nl/lLtwzcrN66/oVgiR9AfgAcAZ4Z9crsnkpd+GL5TU7zawac3bkkn4q6fA0bzsAImJ3RKwFHgQ+Osvn+ZCkg5IOjo6O9q6Cmip35B6tmNXbnB15RGyb5+f6AfBj4LMzfJ49wB6AkZERj2C6VJ6R+2SnWb11u2tlQ+npbcDR7pZj81Wei3v7oVm9dTsjv0/SdcAF4Fngw90vyeajCO8hDTHcGK54NWZWpa6CPCLe36uF2KUpTnD6RKeZ+crORF3WzE5weuuhmTnIE1V04p6Pm5mDPFFFJ+6O3Mwc5IkqOnHPyM3MQZ4od+RmVnCQJ6royH1Vp5k5yBNVdOK+qtPMHOSJ8q4VMys4yBNVdOIOcjNzkCeqoQatZsujFTPr/n7kVp2733A3m1durnoZZlYxB3nC7th0R9VLMLNFwKMVM7PEOcjNzBLnIDczS5yD3MwscQ5yM7PEOcjNzBLnIDczS5yD3MwscYqIhf+i0ijw7P/5118B/LOHy0lFHeuuY81Qz7rrWDNcet2vjohXTj1YSZB3Q9LBiBipeh0LrY5117FmqGfddawZele3RytmZolzkJuZJS7FIN9T9QIqUse661gz1LPuOtYMPao7uRm5mZlNlmJHbmZmJQ5yM7PEJRXkkrZLOibpuKR7ql5PP0haK+nnko5I+r2ku/LjKyQ9Ienp/P2VVa+11yQ1Jf1O0v78eR1qfrmkRyQdzb/nbxr0uiV9Iv/ZPizpIUntQaxZ0rclnZJ0uHRsxjol3Ztn2zFJ77mUr5VMkEtqAl8HbgZuAG6XdEO1q+qLDvDJiNgE3AR8JK/zHuDJiNgAPJk/HzR3AUdKz+tQ81eBn0TE9cBmsvoHtm5Jq4GPASMR8VqgCexkMGv+LrB9yrFp68z/je8EXpP/nW/kmTcvyQQ58EbgeET8OSJeAB4GdlS8pp6LiJMR8dv88b/J/mGvJqv1gfyPPQC8r5oV9oekNcB7gftLhwe95iuAtwF7ASLihYg4zYDXTfYSk5dJGgIuB/7GANYcEb8A/jXl8Ex17gAejoiJiHgGOE6WefOSUpCvBp4vPT+RHxtYkq4FbgQOAK+KiJOQhT2wsrqV9cVXgE8BF0rHBr3m9cAo8J18pHS/pKUMcN0R8VfgS8BzwEngTEQ8zgDXPMVMdXaVbykFuaY5NrB7JyUtA34IfDwizla9nn6SdCtwKiJ+U/VaFtgQ8HrgmxFxI/AfBmOkMKN8JrwDWAdcAyyVdGe1q1oUusq3lIL8BLC29HwN2a9kA0fSMFmIPxgRj+aH/yHp6vzjVwOnqlpfH7wFuE3SX8hGZu+S9H0Gu2bIfqZPRMSB/PkjZME+yHVvA56JiNGIOAc8CryZwa65bKY6u8q3lIL818AGSeskLSE7MbCv4jX1nCSRzUyPRMSXSx/aB+zKH+8CfrTQa+uXiLg3ItZExLVk39efRcSdDHDNABHxd+B5Sdflh7YCf2Cw634OuEnS5fnP+lay80CDXHPZTHXuA3ZKaklaB2wAfjXvzxoRybwBtwB/BP4E7K56PX2q8a1kv1I9BRzK324BriI7y/10/n5F1WvtU/3vAPbnjwe+ZmALcDD/fj8GXDnodQOfA44Ch4HvAa1BrBl4iOw8wDmyjvuDs9UJ7M6z7Rhw86V8LV+ib2aWuJRGK2ZmNg0HuZlZ4hzkZmaJc5CbmSXOQW5mljgHuZlZ4hzkZmaJ+x/GmIbdKkLJ8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sine = np.array([])\n",
    "for i in range(0,n):\n",
    "    noise1 = np.random.normal(0,pi_dev, 100)\n",
    "    sin_noise = sin + noise1\n",
    "    sin_cor = sin + np.random.binomial(1, corruption_rate, 100) * sin_noise\n",
    "    sine = np.append(sine, sin_cor)\n",
    "    \n",
    "sine = np.reshape(sine, newshape = (50, 100))\n",
    "sine = sine.T\n",
    "\n",
    "plt.plot(sin, label = 'Sine', linewidth = 4)\n",
    "for i in range(0, 3):\n",
    "    plt.plot(sine[:,i], label = f'Example Sine {i}')\n",
    "plt.legend()\n",
    "plt.title(\"Example of Corrupted Sine Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 150)\n"
     ]
    }
   ],
   "source": [
    "# X is a data frame containing corrupted Sine, Cosine, and Tangent data\n",
    "# 100 rows of 150 columns, where each column represents 1 of the wave functions\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2f93c9e6940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labs = ['Sine', 'Cosine', 'Tangent']\n",
    "X = X/np.linalg.norm(X)\n",
    "for i in range(0,2):\n",
    "    l = labs[i]\n",
    "    plt.plot(X[:,i], label = f'{l}')\n",
    "plt.title(\"Normalized Corrupted Trig. Functions\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training at varying levels of lambda: \n",
    "Lambda = min(cost)\n",
    "1.0 = 0.52\n",
    "0.5 = 0.06\n",
    "0.2 = 0.014\n",
    "0.10 = 0.0034669712\n",
    "0.01 = 5x10^-0.5\n",
    "0.00065 = 0.0003\n",
    "0.00005 = 1.1x10^-6\n",
    "0.000015 = 2.1x10^-7 # this parameter should be close enough; achieved 1.17x10^-10\n",
    "0.000005 = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train numbers matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### I think the big issue here is I need to understant the following: \n",
    "# What's being fed in (keep column-wise rows?)\n",
    "# What do the iterations need to be set to within the RDAE? \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, c = X.shape\n",
    "r\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L shape: (150,)\n",
      "X size is: 15000 (in case it requires adjusting too)\n",
      "shrink parameter: 0.0008100458669376908\n",
      "X shape:  (100, 150)\n",
      "L shape:  (150,)\n",
      "S shape:  (150,)\n",
      "mu:  6172.489983687063\n",
      "XFnorm:  0.9999999999999999\n",
      "Out iteration:  0\n",
      "    iteration :  0 , cost :  0.013333331\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-071b1c3312a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mrae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRDAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# , 5, 10, 20 # [784,400,255,100]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0ml21R\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetRecon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0ml21H\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-d9e8819ac006>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, sess, learning_rate, inner_iteration, iteration, batch_size, verbose)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;31m### *changed SHR.shrink to l21shrink * ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;31m### * should we be using l21 shrink? ### --> check paper...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSHR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml21shrink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;31m## break criterion 1: the L and S are close enough to X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\projects\\korkin\\RobustAutoencoder\\model\\shrink\\l21shrink.py\u001b[0m in \u001b[0;36ml21shrink\u001b[1;34m(epsilon, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Original \n",
    "if __name__ == \"__main__\":\n",
    "    #x = np.load(r\"../data/data.npk\", allow_pickle = True)[:500]\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        r, c = X.shape\n",
    "        rae = RDAE(sess = sess, lambda_= 5, layers_sizes=[c, round(c * 0.75), c]) # , 5, 10, 20 # [784,400,255,100]\n",
    "        L, S = rae.fit(X, sess = sess, inner_iteration = 1, iteration = 5,verbose = True) \n",
    "        l21R = rae.getRecon(X, sess = sess)\n",
    "        l21H = rae.transform(X, sess)\n",
    "        \n",
    "        # double check the author's implementation... \n",
    "        \n",
    "        # lambda is the balancing parameter that tunes sparsity\n",
    "        # adding these two to the model\n",
    "        #M_Transf=rae.transform(X=X,sess=sess)\n",
    "        #M_Recons = rae.getRecon(X = X, sess = sess)        \n",
    "        \n",
    "# probably need to read the paper! OG paper from Chou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l21R' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a2ef8ae44c80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ml21R\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'l21R' is not defined"
     ]
    }
   ],
   "source": [
    "l21R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.5331848e-08, 3.0224087e-06, 9.9999940e-01, ..., 1.0000000e+00,\n",
       "        9.9999213e-01, 1.0000000e+00],\n",
       "       [9.9999976e-01, 1.0000000e+00, 9.8435915e-01, ..., 9.9257880e-01,\n",
       "        1.0000000e+00, 9.6701741e-01],\n",
       "       [9.9999970e-01, 9.9999940e-01, 9.8849344e-01, ..., 9.9549580e-01,\n",
       "        1.0000000e+00, 9.8032582e-01],\n",
       "       ...,\n",
       "       [1.0000000e+00, 1.0000000e+00, 7.9599619e-03, ..., 2.8147042e-02,\n",
       "        1.0000000e+00, 1.1351913e-02],\n",
       "       [9.9997908e-01, 1.0000000e+00, 9.0959579e-01, ..., 9.8448277e-01,\n",
       "        1.0000000e+00, 9.5124382e-01],\n",
       "       [9.9998736e-01, 9.9999923e-01, 9.8207891e-01, ..., 9.8204499e-01,\n",
       "        9.9999964e-01, 9.4308692e-01]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l21H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.4916950e-26, 1.5794357e-26, 1.3559557e-07, ..., 1.4736749e-17,\n",
       "        2.2704396e-14, 3.1814958e-17],\n",
       "       [9.9301871e-35, 0.0000000e+00, 3.5508408e-24, ..., 2.6828584e-27,\n",
       "        2.0854181e-24, 0.0000000e+00],\n",
       "       [1.6354686e-35, 0.0000000e+00, 2.7868318e-24, ..., 1.3729280e-27,\n",
       "        9.6018325e-25, 0.0000000e+00],\n",
       "       ...,\n",
       "       [5.1893990e-15, 6.0555352e-21, 1.0936715e-19, ..., 1.4072059e-15,\n",
       "        1.0339415e-12, 2.5978230e-30],\n",
       "       [1.4728857e-35, 0.0000000e+00, 2.3754432e-24, ..., 1.6495478e-27,\n",
       "        1.3072086e-24, 0.0000000e+00],\n",
       "       [1.7970470e-35, 0.0000000e+00, 2.1956941e-24, ..., 1.7849070e-27,\n",
       "        1.8456267e-24, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.40164423, -0.11998487, -0.20696882, ..., -0.24139453,\n",
       "         -0.3217942 , -0.21914448],\n",
       "        [-0.40430806, -0.19577946, -0.10214359, ..., -0.217587  ,\n",
       "         -0.33314796, -0.17390105],\n",
       "        [-0.39981699, -0.09300494, -0.15369448, ..., -0.18091456,\n",
       "          1.63036959, -0.26589823],\n",
       "        ...,\n",
       "        [ 1.43616482, -0.15203798, -0.20749758, ..., -0.23861517,\n",
       "          1.63036959, -0.25785576],\n",
       "        [-0.38958276,  0.        , -0.20683139, ..., -0.17745348,\n",
       "         -0.28322888, -0.25721141],\n",
       "        [-0.36601815, -0.03578073, -0.14989704, ..., -0.19319542,\n",
       "         -0.30031159, -0.31458025]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current largest potential problem is that it trains the entire matrix as one data point\n",
    "# that works fine for images, who are legit matrices, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training stops improving.. is LR too low or too high?\n",
    "# also, what are the dims at each point, is this algo taking the entire matrix at once? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   71   72   73   74  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.7  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.7  ...  0.0  0.7  0.0  0.3   \n",
       "2  0.0  0.0  0.0  0.7  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.7  0.0  0.0   \n",
       "3  0.7  0.0  0.0  0.0  0.0  0.0  0.7  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.7  0.0  0.0  0.7  0.0  0.0  0.7  ...  0.3  0.0  0.0  0.0   \n",
       "\n",
       "    75   76   77   78   79   80  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.7  0.0  0.0  0.0  0.5  0.0  \n",
       "3  0.7  0.5  0.0  0.7  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.around(x, 1)[0:5])\n",
    "pd.DataFrame(np.around(L, 1)[0:5])\n",
    "pd.DataFrame(np.around(S, 1)[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1567479 , 0.30905938, 0.52031744, ..., 0.13211042, 0.37644204,\n",
       "        0.5822023 ],\n",
       "       [0.15674827, 0.30906016, 0.5203181 , ..., 0.1321108 , 0.37644285,\n",
       "        0.58220315],\n",
       "       [0.15674832, 0.30906016, 0.52031815, ..., 0.13211086, 0.3764429 ,\n",
       "        0.58220315],\n",
       "       ...,\n",
       "       [0.15674838, 0.30906022, 0.52031815, ..., 0.1321109 , 0.37644297,\n",
       "        0.5822032 ],\n",
       "       [0.15674832, 0.30906016, 0.52031815, ..., 0.13211086, 0.3764429 ,\n",
       "        0.58220315],\n",
       "       [0.15674838, 0.30906016, 0.52031815, ..., 0.1321109 , 0.37644294,\n",
       "        0.58220315]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function around in module numpy:\n",
      "\n",
      "around(a, decimals=0, out=None)\n",
      "    Evenly round to the given number of decimals.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    decimals : int, optional\n",
      "        Number of decimal places to round to (default: 0).  If\n",
      "        decimals is negative, it specifies the number of positions to\n",
      "        the left of the decimal point.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must have\n",
      "        the same shape as the expected output, but the type of the output\n",
      "        values will be cast if necessary. See `ufuncs-output-type` for more\n",
      "        details.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    rounded_array : ndarray\n",
      "        An array of the same type as `a`, containing the rounded values.\n",
      "        Unless `out` was specified, a new array is created.  A reference to\n",
      "        the result is returned.\n",
      "    \n",
      "        The real and imaginary parts of complex numbers are rounded\n",
      "        separately.  The result of rounding a float is a float.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.round : equivalent method\n",
      "    \n",
      "    ceil, fix, floor, rint, trunc\n",
      "    \n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    For values exactly halfway between rounded decimal values, NumPy\n",
      "    rounds to the nearest even value. Thus 1.5 and 2.5 round to 2.0,\n",
      "    -0.5 and 0.5 round to 0.0, etc.\n",
      "    \n",
      "    ``np.around`` uses a fast but sometimes inexact algorithm to round\n",
      "    floating-point datatypes. For positive `decimals` it is equivalent to\n",
      "    ``np.true_divide(np.rint(a * 10**decimals), 10**decimals)``, which has\n",
      "    error due to the inexact representation of decimal fractions in the IEEE\n",
      "    floating point standard [1]_ and errors introduced when scaling by powers\n",
      "    of ten. For instance, note the extra \"1\" in the following:\n",
      "    \n",
      "        >>> np.round(56294995342131.5, 3)\n",
      "        56294995342131.51\n",
      "    \n",
      "    If your goal is to print such values with a fixed number of decimals, it is\n",
      "    preferable to use numpy's float printing routines to limit the number of\n",
      "    printed decimals:\n",
      "    \n",
      "        >>> np.format_float_positional(56294995342131.5, precision=3)\n",
      "        '56294995342131.5'\n",
      "    \n",
      "    The float printing routines use an accurate but much more computationally\n",
      "    demanding algorithm to compute the number of digits after the decimal\n",
      "    point.\n",
      "    \n",
      "    Alternatively, Python's builtin `round` function uses a more accurate\n",
      "    but slower algorithm for 64-bit floating point values:\n",
      "    \n",
      "        >>> round(56294995342131.5, 3)\n",
      "        56294995342131.5\n",
      "        >>> np.round(16.055, 2), round(16.055, 2)  # equals 16.0549999999999997\n",
      "        (16.06, 16.05)\n",
      "    \n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] \"Lecture Notes on the Status of IEEE 754\", William Kahan,\n",
      "           https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF\n",
      "    .. [2] \"How Futile are Mindless Assessments of\n",
      "           Roundoff in Floating-Point Computation?\", William Kahan,\n",
      "           https://people.eecs.berkeley.edu/~wkahan/Mindless.pdf\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.around([0.37, 1.64])\n",
      "    array([0.,  2.])\n",
      "    >>> np.around([0.37, 1.64], decimals=1)\n",
      "    array([0.4,  1.6])\n",
      "    >>> np.around([.5, 1.5, 2.5, 3.5, 4.5]) # rounds to nearest even value\n",
      "    array([0.,  2.,  2.,  4.,  4.])\n",
      "    >>> np.around([1,2,3,11], decimals=1) # ndarray of ints is returned\n",
      "    array([ 1,  2,  3, 11])\n",
      "    >>> np.around([1,2,3,11], decimals=-1)\n",
      "    array([ 0,  0,  0, 10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(np.around(L,1))\n",
    "help(np.around)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49 rows  81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9   ...   71   72   73   74  \\\n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "5   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "13  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "14  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "15  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "16  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "17  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "18  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "19  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "20  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "21  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "22  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "23  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "24  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "25  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "26  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "27  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "28  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "29  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "30  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "31  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "32  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "33  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "34  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "35  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "36  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "37  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "38  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "39  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "40  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "41  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "42  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "43  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "44  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "45  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "46  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "47  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "48  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     75   76   77   78   79   80  \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "10  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "11  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "13  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "14  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "16  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "17  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "18  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "19  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "20  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "21  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "22  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "23  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "24  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "25  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "26  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "27  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "28  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "29  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "30  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "31  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "32  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "33  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "34  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "35  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "36  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "37  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "38  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "39  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "40  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "41  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "42  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "43  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "44  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "45  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "46  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "47  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "48  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[49 rows x 81 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.around(S, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programs\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\programs\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\seaborn\\distributions.py:305: UserWarning: Dataset has 0 variance; skipping density estimate.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "L.shape\n",
    "\n",
    "all = []\n",
    "for i in range(0, L.shape[1]):\n",
    "    all.append(statistics.mean(L[:, i]))\n",
    "\n",
    "all = np.array(all)\n",
    "sns.distplot(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.10046257, ..., 0.        , 0.23688205,\n",
       "         4.18666963],\n",
       "        [0.        , 0.        , 0.29246966, ..., 0.        , 0.13860606,\n",
       "         4.35147569],\n",
       "        [0.        , 0.        , 0.07200625, ..., 0.        , 0.30945149,\n",
       "         4.08131912],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.1205154 , ..., 0.        , 0.28861502,\n",
       "         4.2299734 ],\n",
       "        [0.        , 0.        , 0.2383594 , ..., 0.        , 0.38603865,\n",
       "         4.19121101],\n",
       "        [0.        , 0.        , 0.13528742, ..., 0.        , 0.24790533,\n",
       "         4.28617866]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the challenge is that L is not as expected. L approaches 1 for all values, when it should distinguish 1, 5, 9, 13.. \n",
    "# try different tuning parameters for lambda: \n",
    "### doesn't change anything. \n",
    "\n",
    "# try changing the training of the DAE\n",
    "#### training of 1 row per pred produced l = 0.98 whereas training of entire matrix produced L values of exactly 1.0\n",
    "\n",
    "# try alternate autoencoders: \n",
    "###\n",
    "\n",
    "\n",
    "# lambda is the parameter that tunes sparcity, so if I'm not able to get the balance between L and S that I expect, \n",
    "# I likely need to adjust lambda... however, adjustments to lambda have failed to produce the expected results thus far. \n",
    "# (Even extreme values of labmda)\n",
    "\n",
    "# how do we know what a 'good' lambda is? \n",
    "\n",
    "\n",
    "#### the L2 norm may be the problem as L2 norm aims to reduce noise across the.... not sure where I was going with this. \n",
    "\n",
    "\n",
    "# note\n",
    "# L represents the part of the input data that is well represented by the hidden layer of the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.001, 0.8678, 0.001, 0.8678, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.001, 0.8678, 0.001, 0.8678, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.001, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.001, 0.8678, 0.001, 0.8678, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.001, 0.8678, 0.001, 0.8678, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.001, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.001, 0.8678, 0.001, 0.8678, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.001, 0.8678, 0.001, 0.8678, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678, 0.001, 0.8678, 0.8678, 0.001, 0.001, 0.8678]\n",
      "Length Z (141,)\n",
      "set Z {0.8678, 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programs\\Anaconda\\envs\\tf1\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\programs\\Anaconda\\envs\\tf1\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "L.shape\n",
    "\n",
    "l = np.array(L).flatten()\n",
    "\n",
    "sns.distplot(l) #### NO! should be 4 or 5 points (not 2, maybe was over-fitting)\n",
    "\n",
    "# may be plotting two columns due to bin size? Probably not, but maybe. Should define a different way to sum and \n",
    "# measure the rows. I.e. average each row and plot the averages\n",
    "\n",
    "z = []\n",
    "for i in range(L.shape[0]):\n",
    "    avg = sum(L[i])/len(L[i])\n",
    "    z.append(round(avg, 4))\n",
    "\n",
    "print(z)\n",
    "\n",
    "z = np.array(z)\n",
    "\n",
    "print(\"Length Z\", z.shape)\n",
    "\n",
    "sns.distplot(np.array(z).flatten())\n",
    "\n",
    "print(\"set Z\", set(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size: 20\n",
      "X shape: (1, 20)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'shrink' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-c47a4b55aa8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mrae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRobustL21Autoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# [784,400,255,100]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mLL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mSS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-c21f4c119f31>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, sess, learning_rate, inner_iteration, iteration, batch_size, verbose)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X size:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X shape:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshrink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshrink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shrink' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    LL = []\n",
    "    SS = []\n",
    "    for idx,val in numb.iterrows():\n",
    "        x = np.matrix(numb.iloc[idx,:])\n",
    "        #print(x.shape)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            rae = RobustL21Autoencoder(sess = sess, lambda_= 0.1, layers_sizes=[20, 10, 5, 3]) # [784,400,255,100]\n",
    "            L, S = rae.fit(x, sess = sess, inner_iteration = 5, iteration = 4,verbose = False) \n",
    "            LL.append(L)\n",
    "            SS.append(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RobustL21Autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-52aca44fa4f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### try new code with tf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRobustL21Autoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# [784,400,255,100] # sess = sess,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#LL.append(L)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RobustL21Autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "### try new code with tf2\n",
    "rae = RobustL21Autoencoder(lambda_= 0.1, layers_sizes=[20, 10, 5, 3]) # [784,400,255,100] # sess = sess, \n",
    "\n",
    "L, S = rae.fit(x, inner_iteration = 5, iteration = 4,verbose = False) \n",
    "#LL.append(L)\n",
    "#SS.append(S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L - the 'non-linear manifold' is ALWAYS the SAME!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New workspace: try implementing the new Robust Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as nplin\n",
    "import tensorflow as tf\n",
    "from BasicAutoencoder import DeepAE as DAE\n",
    "from shrink import l1shrink as SHR \n",
    "\n",
    "class RDAE(object):\n",
    "    \"\"\"\n",
    "    @author: Chong Zhou\n",
    "    2.0 version.\n",
    "    complete: 10/17/2016\n",
    "    version changes: move implementation from theano to tensorflow.\n",
    "    3.0\n",
    "    complete: 2/12/2018\n",
    "    changes: delete unused parameter, move shrink function to other file\n",
    "    update: 03/15/2019\n",
    "        update to python3 \n",
    "    Des:\n",
    "        X = L + S\n",
    "        L is a non-linearly low rank matrix and S is a sparse matrix.\n",
    "        argmin ||L - Decoder(Encoder(L))|| + ||S||_1\n",
    "        Use Alternating projection to train model\n",
    "    \"\"\"\n",
    "    def __init__(self, sess, layers_sizes, lambda_=1.0, error = 1.0e-7, inputsize = (1,20)): # added input sizes\n",
    "        \"\"\"\n",
    "        sess: a Tensorflow tf.Session object\n",
    "        layers_sizes: a list that contain the deep ae layer sizes, including the input layer\n",
    "        lambda_: tuning the weight of l1 penalty of S\n",
    "        error: converge criterior for jump out training iteration\n",
    "        \"\"\"\n",
    "        self.lambda_ = lambda_\n",
    "        self.layers_sizes = layers_sizes\n",
    "        self.error = error\n",
    "        self.errors=[]\n",
    "        self.AE = DAE.Deep_Autoencoder( sess = sess, input_dim_list = self.layers_sizes)\n",
    "\n",
    "    def fit(self, X, sess, learning_rate=0.15, inner_iteration = 50,\n",
    "            iteration=20, batch_size=1, verbose=False):\n",
    "        \n",
    "        \n",
    "        ## The first layer must be the input layer, so they should have same sizes.\n",
    "        assert X.shape[1] == self.layers_sizes[0]\n",
    "\n",
    "        ## initialize L, S, mu(shrinkage operator)\n",
    "        self.L = np.zeros(X.shape)\n",
    "        self.S = np.zeros(X.shape)\n",
    "\n",
    "        mu = (X.size) / (4.0 * nplin.norm(X,1))\n",
    "        print (\"shrink parameter:\", self.lambda_ / mu)\n",
    "        LS0 = self.L + self.S\n",
    "        \n",
    "        XFnorm = nplin.norm(X,'fro')\n",
    "        if verbose:\n",
    "            print (\"X shape: \", X.shape)\n",
    "            print (\"L shape: \", self.L.shape)\n",
    "            print (\"S shape: \", self.S.shape)\n",
    "            print (\"mu: \", mu)\n",
    "            print (\"XFnorm: \", XFnorm)\n",
    "\n",
    "        for it in range(iteration):\n",
    "            if verbose:\n",
    "                print (\"Out iteration: \" , it)\n",
    "            ## alternating project, first project to L\n",
    "            self.L = X - self.S\n",
    "            ## Using L to train the auto-encoder\n",
    "            self.AE.fit(X = self.L, sess = sess,\n",
    "                                    iteration = inner_iteration,\n",
    "                                    learning_rate = learning_rate,\n",
    "                                    batch_size = batch_size,\n",
    "                                    verbose = verbose)\n",
    "            ## get optmized L\n",
    "            self.L = self.AE.getRecon(X = self.L, sess = sess)\n",
    "            \n",
    "            ## alternating project, now project to S\n",
    "            self.S = SHR.shrink(self.lambda_/mu, (X - self.L).reshape(X.size)).reshape(X.shape)\n",
    "            \n",
    "            ## break criterion 1: the L and S are close enough to X\n",
    "            c1 = nplin.norm(X - self.L - self.S, 'fro') / XFnorm\n",
    "            ## break criterion 2: there is no changes for L and S \n",
    "            c2 = np.min([mu,np.sqrt(mu)]) * nplin.norm(LS0 - self.L - self.S) / XFnorm\n",
    "\n",
    "            if verbose:\n",
    "                print (\"c1: \", c1)\n",
    "                print (\"c2: \", c2)\n",
    "\n",
    "            if c1 < self.error and c2 < self.error :\n",
    "                print (\"early break\")\n",
    "                break\n",
    "            ## save L + S for c2 check in the next iteration\n",
    "            LS0 = self.L + self.S\n",
    "            \n",
    "        return self.L , self.S\n",
    "    \n",
    "    def transform(self, X, sess):\n",
    "        L = X - self.S\n",
    "        return self.AE.transform(X = L, sess = sess)\n",
    "    \n",
    "    def getRecon(self, X, sess):\n",
    "        return self.AE.getRecon(X, sess = sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shrink parameter: 0.0702166003189276\n",
      "X shape:  (1, 20)\n",
      "L shape:  (1, 20)\n",
      "S shape:  (1, 20)\n",
      "mu:  1.4241646497522609\n",
      "XFnorm:  5.688262550057416\n",
      "Out iteration:  0\n",
      "    iteration :  0 , cost :  249.575\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-553df2cf46f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mrae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRDAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# [784,400,255,100]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-101-d9318171855c>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, sess, learning_rate, inner_iteration, iteration, batch_size, verbose)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;31m## alternating project, now project to S\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSHR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshrink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;31m## break criterion 1: the L and S are close enough to X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\projects\\korkin\\RobustAutoencoder\\model\\shrink\\l1shrink.py\u001b[0m in \u001b[0;36mshrink\u001b[1;34m(epsilon, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mele\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mele\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mele\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mele\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #x = np.load(r\"../data/data.npk\", allow_pickle = True)[:500]\n",
    "    for idx,val in numb.iterrows():\n",
    "        x = np.matrix(numb.iloc[idx,:])\n",
    "        \n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            rae = RDAE(sess = sess, lambda_= 0.1*x.shape[0], layers_sizes=[20, 10, 5, 3]) # [784,400,255,100]\n",
    "            L, S = rae.fit(x, sess = sess, inner_iteration = 1, iteration = 4,verbose = True) \n",
    "            M_Transf=rae.transform(X=X,sess=sess)\n",
    "            M_Recons = rae.getRecon(X = X, sess = sess) # added these last two... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsilon comparison is still messed up. Check if epsilon is an array or a single integer. \n",
    "\n",
    "for idx,val in numb.iterrows():\n",
    "    yy = np.matrix(numb.iloc[idx,:])\n",
    "    #print(yy.shape)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shrink is not working becaquse x is matrix rather than a vector. Need to feed data in one row at a time. \n",
    "\n",
    "# I need to ensure x is a vector! I think this is my fault it's not working. \n",
    "\n",
    "# check how HE trained images: \n",
    "\n",
    "def shrink(epsilon, x): \n",
    "    \"\"\"\n",
    "    @Original Author: Prof. Randy\n",
    "    @Modified by: Chong Zhou\n",
    "    update to python3: 03/15/2019\n",
    "    Args:\n",
    "        epsilon: the shrinkage parameter (either a scalar or a vector)\n",
    "        x: the vector to shrink on\n",
    "\n",
    "    Returns:\n",
    "        The shrunk vector\n",
    "    \"\"\"\n",
    "    output = np.array(x*0.)\n",
    "\n",
    "    for idx, ele in enumerate(x):\n",
    "        if ele > epsilon:\n",
    "            output[idx] = ele - epsilon\n",
    "        elif ele < -epsilon:\n",
    "            output[idx] = ele + epsilon\n",
    "        else:\n",
    "            output[idx] = 0.\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enumerate object at 0x000001695325DFC0>\n",
      "0\n",
      "[[ 2.68908254  0.20377624 -0.65410784  0.76755269  2.53570324  0.97765769\n",
      "   0.15350844 -0.15789158  1.58324769  4.09399943 -0.33717254  1.39267646\n",
      "   1.50037684  0.14434595  2.86836397  0.86329883 -1.5124115   1.62483521\n",
      "   1.44079755  1.36877674]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-338b53b71453>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mele\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mele\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mele\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mele\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# can prob scrap this once I figure out how to feed a vector. \n",
    "epsilon = 1\n",
    "for i in x:\n",
    "    output = np.array(x*0.)\n",
    "        \n",
    "    for idx, ele in enumerate(i):\n",
    "        print(idx)\n",
    "        print(ele)\n",
    "        if ele > epsilon:\n",
    "            output[idx] = ele - epsilon\n",
    "        elif ele < -epsilon:\n",
    "            output[idx] = ele + epsilon\n",
    "        else:\n",
    "            output[idx] = 0.\n",
    "\n",
    "            \n",
    "            #return output\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes as of 6.9.2020:\n",
    "I've been playing around with my 'numbers' data set, working to train the robust deep autoencoder. \n",
    "This should be a pretty simple task, I expect the algorithm to predict the groups of data pretty well (1, 5, 9, and 13). There is one occurrence of 30 which I expect to be detected as an outlier. \n",
    "\n",
    "What is happening is that as the network trains, L converges towards some mean value and S ends up capturing the meaningful differences between groups. To me, this process represents overfitting. I have been trying to get cost down as close to zero as possible, but maybe that's the issue. Low cost indicates potential over-fitting. \n",
    "\n",
    "Lambda is the parameter of importance for the S matrix. When lambda is small, the shrinkage function is given little weight.\n",
    "Setting labmda to 1 actually seems to prevent overfitting. When lambda is set to0 low, S will be completely sparse.\n",
    "\n",
    "As the cost decreases, the unique groups within x become similar. -- actually not true\n",
    "As the minimum layer size (size of the decoder input) gets smaller, the range of unique values generated in the output tends to decrease. So this is basically saying that as we give the network less flexibility (range) to express itself, its is forced to express itself more concisely. It makes better use of the low-dimensional values, where a slight change in an embedding value yields a completely different classification. All of this makes sense. \n",
    "\n",
    "However, when the cost is minimized, in some cases... the autoencoder starts to yield L values that are exactly the same (even among classes) and S is left containing the differences between the data points. In some sense it makes sense that this would happen, but it also strikes me that this is overfitting. L should produce clear, denoised components. \n",
    "\n",
    "Right now I can't tell whether a given data point is 'denoised' because I don't have noisy data points, I only have one outlier. So going forward, I should use the random function to add a bit of noise to each element, in each row in the data set. \n",
    "Then I can see if the true values are recoverable. If so, it's working. If not, need to re-evaluate. \n",
    "\n",
    "Then, I need to learn how to feed data into the model to get the encoded values for each data point. Doing that, I can then cluster the data points into it's natural groupings and make sure that the process works. After that, I am ready to try it on the yeast data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update as of 6.14.2020:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm still working to discover why the function isn't recovering the data in L. It could be that the problem is I am optimizing across the entire matrix when I need to focus on optimizing across a single vector at a time. I'm not exactly sure how to do that yet. I've tried using a batch size of one, but expected values are not returned. I think even with batch size of one the enitre matrix is optimized across the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial Deconfounding Autoencoder for Learning Robust Gene Expression Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-682499b8c6a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-682499b8c6a1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "[(i) for i in L]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn histograms indicate that S is capturing most of the distinguishing features of the values and L is capturing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #x = np.load(r\"../data/data.npk\", allow_pickle = True)[:500]\n",
    "    x = np.matrix(numbers)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        #rae = RobustL21Autoencoder(sess = sess, lambda_=0.000015, layers_sizes=[17, 12, 8, 1]) # [784,400,255,100]\n",
    "        rae = RobustL21Autoencoder(sess = sess, lambda_=200, layers_sizes=[20, 12]) # [784,400,255,100]\n",
    "        # 17, 12, 10, 8\n",
    "\n",
    "        #rae = RDAE(sess = sess, lambda_=0.015, layers_sizes=[17, 12, 8, 1])\n",
    "        \n",
    "        L, S = rae.fit(x, sess = sess, inner_iteration = 60, iteration = 5,verbose = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20.0}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = [round(i.sum(),3) for i in L]\n",
    "set(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Yeung Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "yeung = pd.read_csv(\"D:\\projects\\korkin\\yeung_raw_cellcycle_384_17.txt\", sep = \"\\t\", low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim df white spaces\n",
    "def trim_all_columns(df):\n",
    "    \"\"\"\n",
    "    Trim whitespace from ends of each value across all series in dataframe\n",
    "    \"\"\"\n",
    "    trim_strings = lambda x: x.strip() if isinstance(x, str) else x\n",
    "    return df.applymap(trim_strings)\n",
    "\n",
    "yeung = trim_all_columns(yeung)\n",
    "\n",
    "# Rename columns\n",
    "yeung = yeung.rename(columns = {'Unnamed: 0': 'orf', 'Main Gp': 'phase'})\n",
    "\n",
    "# Convert phase column to string\n",
    "yeung['phase'] = yeung.phase.astype(str)\n",
    "\n",
    "# Trim whitespace (if they exist) from column names\n",
    "yeung.rename(columns=lambda x: x.strip(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all time point columns as int type\n",
    "for column in yeung.columns:\n",
    "    if yeung[column].dtype == 'int64':\n",
    "        # set column name as 'x'\n",
    "        x = yeung[column]\n",
    "        \n",
    "        # subtract the mean of x from each value of x\n",
    "        x -= np.mean(x)\n",
    "        \n",
    "        # divide each value in the array by the standard deviation of the array\n",
    "        x /= np.std(x)\n",
    "        \n",
    "        # replace prior values with z-score values\n",
    "        yeung[column] = x\n",
    "yeung = yeung.iloc[:,2:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #x = np.load(r\"../data/data.npk\", allow_pickle = True)[:500]\n",
    "    x = np.matrix(yeung)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        #rae = RobustL21Autoencoder(sess = sess, lambda_=0.000015, layers_sizes=[17, 12, 8, 1]) # [784,400,255,100]\n",
    "        rae = RobustL21Autoencoder(sess = sess, lambda_=1, layers_sizes=[17, 12, 8, 3]) # [784,400,255,100]\n",
    "        # 17, 12, 10, 8\n",
    "        #rae = RDAE(sess = sess, lambda_=0.015, layers_sizes=[17, 12, 8, 1])\n",
    "        \n",
    "        L, S = rae.fit(x, sess = sess, inner_iteration = 20, iteration = 5,verbose = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find epsilon in his work, does he define it as an array? If so, may fix my problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try clustering L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if natural clusters are detected. If so, may be working correctly. If not, can't trust it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test out RobustDeepAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shrink parameter: 238.91048326357938\n",
      "X shape:  (20, 20)\n",
      "L shape:  (20, 20)\n",
      "S shape:  (20, 20)\n",
      "mu:  8.371336295835492\n",
      "XFnorm:  20.0\n",
      "Out iteration:  0\n",
      "    iteration :  0 , cost :  255.39145\n",
      "    iteration :  20 , cost :  246.89925\n",
      "    iteration :  40 , cost :  239.32169\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-1ceb19b2e475>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         L, S = rae.fit(x ,sess = sess, learning_rate=0.01, batch_size = 40, inner_iteration = 50, \\\n\u001b[1;32m---> 11\u001b[1;33m                 iteration=1, verbose=True)\n\u001b[0m",
      "\u001b[1;32m~\\projects\\korkin\\RobustAutoencoder\\model\\RobustDeepAutoencoder.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, sess, learning_rate, inner_iteration, iteration, batch_size, verbose)\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetRecon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;31m## alternating project, now project to S\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSHR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshrink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;31m## break criterion 1: the L and S are close enough to X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\projects\\korkin\\RobustAutoencoder\\model\\shrink\\l1shrink.py\u001b[0m in \u001b[0;36mshrink\u001b[1;34m(epsilon, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mele\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mele\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mele\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mele\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # = np.load(r\"../data/data.npk\")[:500]\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        x = np.matrix(numbers)\n",
    "         \n",
    "        rae = RDAE(sess = sess, lambda_= 2000, layers_sizes=[20, 14, 8])\n",
    "\n",
    "        L, S = rae.fit(x ,sess = sess, learning_rate=0.01, batch_size = 40, inner_iteration = 50, \\\n",
    "                iteration=1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### notes as of 6/8/2020\n",
    "The RobustAutoencoder is not working properly. This is likely because of the l1shrink function (RAE uses l21shrink).\n",
    "l1shrink is currently failing because it utilizes enumerate() to process the function but we are feeding a matrix to l1shrink\n",
    "and enumerate doesn't return elementwise pieces it returns the whole matrix. So I need to rewrite this function so that it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #recon_rae = rae.getRecon(x, sess = sess)\n",
    "\n",
    "        #print (\"cost errors, not used for now:\", rae.errors)\n",
    "    #from collections import Counter\n",
    "    #print (\"number of zero values in S:\", Counter(S.reshape(S.size))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test out with my pseudo data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now what do we do with matrix L and S? \n",
    "# Use L for clustering? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 17)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.matrix(data)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-503d3ab4a9b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# create session, sess.run() function then evaluates the tensor and returns the results.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run(tf_t) : \\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf_t' is not defined"
     ]
    }
   ],
   "source": [
    "# Original code: \n",
    "\n",
    "sess=tf.Session() # create session, sess.run() function then evaluates the tensor and returns the results.\n",
    "\n",
    "#print('run(tf_t) : \\n', sess.run(tf_t))\n",
    "\n",
    "with sess.as_default():\n",
    "# args: self, sess, layers_sizes, lambda_=1.0, error = 1.0e-5\n",
    "    \n",
    "    # x = np.array(data.iloc[0,:])\n",
    "    autoencoder = RobustL21Autoencoder(sess = sess, layers_sizes = [20, 16, 8, 4])\n",
    "    L, S = autoencoder.fit(x, sess= sess, verbose = True)\n",
    "    \n",
    "sess.close()#close session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x20654df9b38>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot execute operation using `run()`: No default session is registered. Use `with sess.as_default():` or pass an explicit session to `run(session=sess)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-fef4862cb96f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\programs\\Anaconda\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m   2437\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2438\u001b[0m     \"\"\"\n\u001b[1;32m-> 2439\u001b[1;33m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2441\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gradient\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\Anaconda\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[1;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   5426\u001b[0m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5427\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5428\u001b[1;33m       raise ValueError(\"Cannot execute operation using `run()`: No default \"\n\u001b[0m\u001b[0;32m   5429\u001b[0m                        \u001b[1;34m\"session is registered. Use `with \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5430\u001b[0m                        \u001b[1;34m\"sess.as_default():` or pass an explicit session to \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot execute operation using `run()`: No default session is registered. Use `with sess.as_default():` or pass an explicit session to `run(session=sess)`"
     ]
    }
   ],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink(epsilon, x):\n",
    "    \"\"\"\n",
    "    @Original Author: Prof. Randy\n",
    "    @Modified by: Chong Zhou\n",
    "    update to python3: 03/15/2019\n",
    "    Args:\n",
    "        epsilon: the shrinkage parameter (either a scalar or a vector)\n",
    "        x: the vector to shrink on\n",
    "\n",
    "    Returns:\n",
    "        The shrunk vector\n",
    "    \"\"\"\n",
    "    output = np.array(x*0.)\n",
    "\n",
    "    for idx, ele in enumerate(x):\n",
    "        if ele > epsilon:\n",
    "            output[idx] = ele - epsilon\n",
    "        elif ele < -epsilon:\n",
    "            output[idx] = ele + epsilon\n",
    "        else:\n",
    "            output[idx] = 0.\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>()>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    with tf.Graph().as_default():\n",
    "        with tf.Session() as sess:\n",
    "            rael21 = l21RDAE.RobustL21Autoencoder(sess = sess, lambda_= lamda*X.shape[0], layers_sizes=layers)\n",
    "            l21L, l21S = rael21.fit(X = X, sess = sess, inner_iteration = inner, \\\n",
    "                            iteration = outer, batch_size = batch_size, learning_rate = learning_rate,  verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-65e0affae225>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtf_t\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mrael21\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRobustL21Autoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_t\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mlayers_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-0df4b00277cb>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess, layers_sizes, lambda_, error)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDAE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeep_Autoencoder\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     def fit(self, X, sess, learning_rate=0.15, inner_iteration = 50,\n",
      "\u001b[1;32m~\\projects\\korkin\\RobustAutoencoder\\model\\BasicAutoencoder\\DeepAE.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess, input_dim_list)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m#         self.cost = 200*tf.losses.log_loss(self.recon, self.input_x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     def fit(self, X, sess, learning_rate=0.15,\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "# example code\n",
    "layers = [10, 5, 10]\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        tf_t=tf.convert_to_tensor(data,dtype=tf.float64)\n",
    "        rael21 = RobustL21Autoencoder(tf_t,  layers_sizes=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow needs graph and Session to compute. \n",
    "# The first step of the startup graph is to create a Session object. \n",
    "# If there are no creation parameters, the Session builder will start the default graph.\n",
    "# Session manages all resources of the TensorFlow program runtime. \n",
    "# The Session needs to be closed after all calculations are completed to help the system recycle resources, \n",
    "# otherwise the problem of resource leakage may occur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-louvain\n",
    "from community import community_louvain\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Louvain Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-40-ff2856ab447d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-40-ff2856ab447d>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    sep = '\\t', low_memory = False)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#scerv = pd.read_csv(\"C:\\\\Users\\\\user\\\\projects\\\\korkin\\\\RobustAutoencoder\\\\model\\\\SaccharomycesCerevisiaeS288C_htb_hq.txt\", \\\n",
    "                   sep = '\\t', low_memory = False)\n",
    "#scerv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniprot_A</th>\n",
       "      <th>Uniprot_B</th>\n",
       "      <th>Gene_A</th>\n",
       "      <th>Gene_B</th>\n",
       "      <th>ORF_A</th>\n",
       "      <th>ORF_B</th>\n",
       "      <th>Alias_A</th>\n",
       "      <th>Alias_B</th>\n",
       "      <th>pmid:method:quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A023PYF7</td>\n",
       "      <td>P39743</td>\n",
       "      <td>A0A023PYF7</td>\n",
       "      <td>RVS167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D9509.8</td>\n",
       "      <td>S000028763</td>\n",
       "      <td>S000002796</td>\n",
       "      <td>19841731:0398:HT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A250W8A7</td>\n",
       "      <td>A0A250W8A7</td>\n",
       "      <td>YSP2</td>\n",
       "      <td>YSP2</td>\n",
       "      <td>SCKG_0199</td>\n",
       "      <td>SCKG_0199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29467216:0114:LC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A250WL92</td>\n",
       "      <td>A0A250WL92</td>\n",
       "      <td>LAM4</td>\n",
       "      <td>LAM4</td>\n",
       "      <td>SCKG_4597</td>\n",
       "      <td>SCKG_4597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29463678:0114:LC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2P2R3</td>\n",
       "      <td>P04821</td>\n",
       "      <td>A2P2R3</td>\n",
       "      <td>CDC25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2142.6</td>\n",
       "      <td>S000004689</td>\n",
       "      <td>S000004301</td>\n",
       "      <td>19841731:0018:HT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2P2R3</td>\n",
       "      <td>P38753</td>\n",
       "      <td>A2P2R3</td>\n",
       "      <td>HSE1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S000004689</td>\n",
       "      <td>S000000994</td>\n",
       "      <td>19841731:0018:HT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23197</th>\n",
       "      <td>Q99312</td>\n",
       "      <td>Q99312</td>\n",
       "      <td>ISN1</td>\n",
       "      <td>ISN1</td>\n",
       "      <td>O3548</td>\n",
       "      <td>O3548</td>\n",
       "      <td>S000005681</td>\n",
       "      <td>S000005681</td>\n",
       "      <td>11283351:0018:HT|11283351:0399:HT|11283351:039...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23198</th>\n",
       "      <td>Q99315</td>\n",
       "      <td>Q99315</td>\n",
       "      <td>TY3B-G</td>\n",
       "      <td>TY3B-G</td>\n",
       "      <td>G5984</td>\n",
       "      <td>G5984</td>\n",
       "      <td>S000007347</td>\n",
       "      <td>S000007347</td>\n",
       "      <td>24608367:0114:LC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23199</th>\n",
       "      <td>Q99380</td>\n",
       "      <td>Q99380</td>\n",
       "      <td>OST4</td>\n",
       "      <td>OST4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S000002391</td>\n",
       "      <td>S000002391</td>\n",
       "      <td>16096345:0090:LC|16754853:0007:LC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23200</th>\n",
       "      <td>Q99385</td>\n",
       "      <td>Q99385</td>\n",
       "      <td>VCX1</td>\n",
       "      <td>VCX1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S000002286</td>\n",
       "      <td>S000002286</td>\n",
       "      <td>23685453:0114:LC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23201</th>\n",
       "      <td>Q9ZZW7</td>\n",
       "      <td>Q9ZZW7</td>\n",
       "      <td>BI3</td>\n",
       "      <td>BI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S000007272</td>\n",
       "      <td>S000007272</td>\n",
       "      <td>16116439:0114:LC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23202 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Uniprot_A   Uniprot_B      Gene_A  Gene_B      ORF_A      ORF_B  \\\n",
       "0      A0A023PYF7      P39743  A0A023PYF7  RVS167        NaN    D9509.8   \n",
       "1      A0A250W8A7  A0A250W8A7        YSP2    YSP2  SCKG_0199  SCKG_0199   \n",
       "2      A0A250WL92  A0A250WL92        LAM4    LAM4  SCKG_4597  SCKG_4597   \n",
       "3          A2P2R3      P04821      A2P2R3   CDC25        NaN    L2142.6   \n",
       "4          A2P2R3      P38753      A2P2R3    HSE1        NaN        NaN   \n",
       "...           ...         ...         ...     ...        ...        ...   \n",
       "23197      Q99312      Q99312        ISN1    ISN1      O3548      O3548   \n",
       "23198      Q99315      Q99315      TY3B-G  TY3B-G      G5984      G5984   \n",
       "23199      Q99380      Q99380        OST4    OST4        NaN        NaN   \n",
       "23200      Q99385      Q99385        VCX1    VCX1        NaN        NaN   \n",
       "23201      Q9ZZW7      Q9ZZW7         BI3     BI3        NaN        NaN   \n",
       "\n",
       "          Alias_A     Alias_B  \\\n",
       "0      S000028763  S000002796   \n",
       "1             NaN         NaN   \n",
       "2             NaN         NaN   \n",
       "3      S000004689  S000004301   \n",
       "4      S000004689  S000000994   \n",
       "...           ...         ...   \n",
       "23197  S000005681  S000005681   \n",
       "23198  S000007347  S000007347   \n",
       "23199  S000002391  S000002391   \n",
       "23200  S000002286  S000002286   \n",
       "23201  S000007272  S000007272   \n",
       "\n",
       "                                     pmid:method:quality  \n",
       "0                                       19841731:0398:HT  \n",
       "1                                       29467216:0114:LC  \n",
       "2                                       29463678:0114:LC  \n",
       "3                                       19841731:0018:HT  \n",
       "4                                       19841731:0018:HT  \n",
       "...                                                  ...  \n",
       "23197  11283351:0018:HT|11283351:0399:HT|11283351:039...  \n",
       "23198                                   24608367:0114:LC  \n",
       "23199                  16096345:0090:LC|16754853:0007:LC  \n",
       "23200                                   23685453:0114:LC  \n",
       "23201                                   16116439:0114:LC  \n",
       "\n",
       "[23202 rows x 9 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in and try evaluating the binary data\n",
    "scerv = pd.read_csv(\"C:\\\\Users\\\\user\\\\projects\\\\korkin\\\\RobustAutoencoder\\\\model\\\\SaccharomycesCerevisiaeS288C_binary_hq.txt\",\n",
    "                   sep = '\\t', low_memory = False)\n",
    "scerv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniprot_A</th>\n",
       "      <th>Uniprot_B</th>\n",
       "      <th>Gene_A</th>\n",
       "      <th>Gene_B</th>\n",
       "      <th>ORF_A</th>\n",
       "      <th>ORF_B</th>\n",
       "      <th>Alias_A</th>\n",
       "      <th>Alias_B</th>\n",
       "      <th>pmid:method:quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A023PXH6</td>\n",
       "      <td>P10592</td>\n",
       "      <td>A0A023PXH6</td>\n",
       "      <td>SSA2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L0931</td>\n",
       "      <td>S000004782</td>\n",
       "      <td>S000003947</td>\n",
       "      <td>19536198:0676:HT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A023PXI0</td>\n",
       "      <td>P11484</td>\n",
       "      <td>A0A023PXI0</td>\n",
       "      <td>SSB1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S000004922</td>\n",
       "      <td>S000002388</td>\n",
       "      <td>19536198:0676:HT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A023PZ99</td>\n",
       "      <td>P10591</td>\n",
       "      <td>A0A023PZ99</td>\n",
       "      <td>SSA1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S000002415</td>\n",
       "      <td>S000000004</td>\n",
       "      <td>19536198:0676:HT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A023PZA9</td>\n",
       "      <td>P25491</td>\n",
       "      <td>A0A023PZA9</td>\n",
       "      <td>YDJ1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N2418|YNL2418C</td>\n",
       "      <td>S000002638</td>\n",
       "      <td>S000005008</td>\n",
       "      <td>19536198:0676:HT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A023PZE6</td>\n",
       "      <td>P39102</td>\n",
       "      <td>A0A023PZE6</td>\n",
       "      <td>XDJ1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L9449.3</td>\n",
       "      <td>S000002455</td>\n",
       "      <td>S000004080</td>\n",
       "      <td>19536198:0676:HT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64605</th>\n",
       "      <td>Q99207</td>\n",
       "      <td>Q99207</td>\n",
       "      <td>NOP14</td>\n",
       "      <td>NOP14</td>\n",
       "      <td>D1566</td>\n",
       "      <td>D1566</td>\n",
       "      <td>S000002307</td>\n",
       "      <td>S000002307</td>\n",
       "      <td>12150911:0004:HT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64606</th>\n",
       "      <td>Q99258</td>\n",
       "      <td>Q99258</td>\n",
       "      <td>RIB3</td>\n",
       "      <td>RIB3</td>\n",
       "      <td>D8035.30</td>\n",
       "      <td>D8035.30</td>\n",
       "      <td>S000002895</td>\n",
       "      <td>S000002895</td>\n",
       "      <td>11805826:0676:HT|11805826:0007:HT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64607</th>\n",
       "      <td>Q99287</td>\n",
       "      <td>Q99287</td>\n",
       "      <td>SEY1</td>\n",
       "      <td>SEY1</td>\n",
       "      <td>O3590</td>\n",
       "      <td>O3590</td>\n",
       "      <td>S000005691</td>\n",
       "      <td>S000005691</td>\n",
       "      <td>22940862:0004:HT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64608</th>\n",
       "      <td>Q99321</td>\n",
       "      <td>Q99321</td>\n",
       "      <td>DDP1</td>\n",
       "      <td>DDP1</td>\n",
       "      <td>O3575</td>\n",
       "      <td>O3575</td>\n",
       "      <td>S000005689</td>\n",
       "      <td>S000005689</td>\n",
       "      <td>22940862:0004:HT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64609</th>\n",
       "      <td>Q99394</td>\n",
       "      <td>Q9URQ5</td>\n",
       "      <td>TRS33</td>\n",
       "      <td>HTL1</td>\n",
       "      <td>O3251|YOR3251C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S000005641</td>\n",
       "      <td>S000006439</td>\n",
       "      <td>16554755:0676:HT|16554755:0004:HT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64610 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Uniprot_A Uniprot_B      Gene_A Gene_B           ORF_A  \\\n",
       "0      A0A023PXH6    P10592  A0A023PXH6   SSA2             NaN   \n",
       "1      A0A023PXI0    P11484  A0A023PXI0   SSB1             NaN   \n",
       "2      A0A023PZ99    P10591  A0A023PZ99   SSA1             NaN   \n",
       "3      A0A023PZA9    P25491  A0A023PZA9   YDJ1             NaN   \n",
       "4      A0A023PZE6    P39102  A0A023PZE6   XDJ1             NaN   \n",
       "...           ...       ...         ...    ...             ...   \n",
       "64605      Q99207    Q99207       NOP14  NOP14           D1566   \n",
       "64606      Q99258    Q99258        RIB3   RIB3        D8035.30   \n",
       "64607      Q99287    Q99287        SEY1   SEY1           O3590   \n",
       "64608      Q99321    Q99321        DDP1   DDP1           O3575   \n",
       "64609      Q99394    Q9URQ5       TRS33   HTL1  O3251|YOR3251C   \n",
       "\n",
       "                ORF_B     Alias_A     Alias_B  \\\n",
       "0               L0931  S000004782  S000003947   \n",
       "1                 NaN  S000004922  S000002388   \n",
       "2                 NaN  S000002415  S000000004   \n",
       "3      N2418|YNL2418C  S000002638  S000005008   \n",
       "4             L9449.3  S000002455  S000004080   \n",
       "...               ...         ...         ...   \n",
       "64605           D1566  S000002307  S000002307   \n",
       "64606        D8035.30  S000002895  S000002895   \n",
       "64607           O3590  S000005691  S000005691   \n",
       "64608           O3575  S000005689  S000005689   \n",
       "64609             NaN  S000005641  S000006439   \n",
       "\n",
       "                     pmid:method:quality  \n",
       "0                       19536198:0676:HT  \n",
       "1                       19536198:0676:HT  \n",
       "2                       19536198:0676:HT  \n",
       "3                       19536198:0676:HT  \n",
       "4                       19536198:0676:HT  \n",
       "...                                  ...  \n",
       "64605                   12150911:0004:HT  \n",
       "64606  11805826:0676:HT|11805826:0007:HT  \n",
       "64607                   22940862:0004:HT  \n",
       "64608                   22940862:0004:HT  \n",
       "64609  16554755:0676:HT|16554755:0004:HT  \n",
       "\n",
       "[64610 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in and evaluate hihgh-throughput co-complex data\n",
    "#scerv = pd.read_csv(\"C:\\\\Users\\\\user\\\\projects\\\\korkin\\\\RobustAutoencoder\\\\model\\\\SaccharomycesCerevisiaeS288C_htc_hq.txt\",\\\n",
    "                   low_memory = False, sep = '\\t')\n",
    "#scerv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19084\n"
     ]
    }
   ],
   "source": [
    "scerv = scerv.loc[:,['Gene_A', 'Gene_B']]\n",
    "print(len(scerv)) # 19085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23202\n"
     ]
    }
   ],
   "source": [
    "scerv = scerv.loc[:,['Uniprot_A', 'Uniprot_B']]\n",
    "print(len(scerv)) # 19085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scerv = scerv.loc[:,['Uniprot_A', 'Uniprot_B']]\n",
    "# Determine how many genes in the data set\n",
    "#len(set(scerv['Uniprot_A'].values.tolist() + scerv['Uniprot_B'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Gene_A'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\programs\\Anaconda\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Gene_A'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-59649cc10f15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Determine how many genes in the data set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscerv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Gene_A'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mscerv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Gene_B'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 5030 unique genes. # Korkin found 5,687 genes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\programs\\Anaconda\\envs\\tf1\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\Anaconda\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Gene_A'"
     ]
    }
   ],
   "source": [
    "# Determine how many genes in the data set\n",
    "len(set(scerv['Gene_A'].values.tolist() + scerv['Gene_B'].values.tolist())) # 5030 unique genes. # Korkin found 5,687 genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEFTOFF HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of communities being produced in my work does not equal that of the paper.  Possible reasons could be that I am using the woring data, \n",
    "# that I am creating the graph using the improper method, that I am running the louvain algorithm improperly. \n",
    "\n",
    "# I think I have the louvain algo running properly, doesn't seem easy to mess up. \n",
    "# I think what's most likely is that I'm creating the graph improperly.... that's the best place to start. \n",
    "\n",
    "# Using nx.from_pandas_edgelist seemed to work!!!! It's not perfect but I have 93 communities now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying high-throughput co-complexe data --> only produce 16 or 19 communities... kinda weird. Doesn't \n",
    "# seem to be the appropriate set. Will have to examine in more detail later. \n",
    "# model genes or proteins? Makes sense to use genes since we're trying to model expression profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Gene_A'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\programs\\Anaconda\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Gene_A'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d76503dafd4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# from_pandas_edgelist(df, source='source', target='target', edge_attr=None, create_using=None)[source]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pandas_edgelist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscerv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Gene_A'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Gene_B'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\Anaconda\\envs\\tf1\\lib\\site-packages\\networkx\\convert_matrix.py\u001b[0m in \u001b[0;36mfrom_pandas_edgelist\u001b[1;34m(df, source, target, edge_attr, create_using)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0medge_attr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\Anaconda\\envs\\tf1\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\Anaconda\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Gene_A'"
     ]
    }
   ],
   "source": [
    "# from_pandas_edgelist(df, source='source', target='target', edge_attr=None, create_using=None)[source]\n",
    "\n",
    "G = nx.from_pandas_edgelist(scerv, source = 'Gene_A', target = 'Gene_B')\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try protein protein interaction network instead\n",
    "G = nx.from_pandas_edgelist(scerv, source = 'Uniprot_A', target = 'Uniprot_B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph and partition\n",
    "partition = community_louvain.best_partition(G)\n",
    "\n",
    "# Resource on different networkx plots: https://networkx.github.io/documentation/stable/auto_examples/drawing/plot_edge_colormap.html#sphx-glr-auto-examples-drawing-plot-edge-colormap-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A0A023PYF7': 0,\n",
       " 'P39743': 0,\n",
       " 'A0A250W8A7': 1,\n",
       " 'A0A250WL92': 2,\n",
       " 'A2P2R3': 0,\n",
       " 'P04821': 0,\n",
       " 'P38753': 0,\n",
       " 'D6VPM8': 3,\n",
       " 'P38723': 4,\n",
       " 'Q12328': 3,\n",
       " 'D6VTK4': 3,\n",
       " 'P08539': 5,\n",
       " 'P18851': 6,\n",
       " 'P32435': 3,\n",
       " 'P32793': 0,\n",
       " 'P32844': 3,\n",
       " 'P53285': 3,\n",
       " 'Q08646': 3,\n",
       " 'Q08929': 4,\n",
       " 'D6W196': 7,\n",
       " 'P29704': 7,\n",
       " 'P53983': 4,\n",
       " 'E9P8D2': 8,\n",
       " 'O13297': 9,\n",
       " 'P04050': 9,\n",
       " 'Q01159': 9,\n",
       " 'O13329': 0,\n",
       " 'P06700': 10,\n",
       " 'P06843': 11,\n",
       " 'P17123': 0,\n",
       " 'P22216': 12,\n",
       " 'P32605': 13,\n",
       " 'P32902': 6,\n",
       " 'P38633': 13,\n",
       " 'P38987': 5,\n",
       " 'P40089': 14,\n",
       " 'P47035': 9,\n",
       " 'Q00916': 0,\n",
       " 'Q02208': 15,\n",
       " 'Q03776': 0,\n",
       " 'Q12072': 0,\n",
       " 'Q12457': 6,\n",
       " 'O13512': 14,\n",
       " 'O13567': 14,\n",
       " 'O13517': 16,\n",
       " 'P40971': 16,\n",
       " 'O13518': 17,\n",
       " 'P32841': 17,\n",
       " 'O13519': 3,\n",
       " 'P19657': 3,\n",
       " 'P38260': 3,\n",
       " 'O13525': 10,\n",
       " 'P27680': 10,\n",
       " 'Q05779': 10,\n",
       " 'O13527': 14,\n",
       " 'P53550': 14,\n",
       " 'O13530': 5,\n",
       " 'P21825': 4,\n",
       " 'P39534': 5,\n",
       " 'O13531': 18,\n",
       " 'P39940': 18,\n",
       " 'P40568': 6,\n",
       " 'P43582': 18,\n",
       " 'Q02574': 13,\n",
       " 'Q06525': 18,\n",
       " 'O13532': 6,\n",
       " 'P47128': 6,\n",
       " 'O13535': 0,\n",
       " 'P36006': 0,\n",
       " 'O13537': 10,\n",
       " 'P03069': 10,\n",
       " 'P53541': 10,\n",
       " 'O13539': 6,\n",
       " 'P33441': 6,\n",
       " 'P40014': 6,\n",
       " 'P47076': 9,\n",
       " 'P53552': 6,\n",
       " 'P53959': 6,\n",
       " 'Q06410': 6,\n",
       " 'Q08118': 0,\n",
       " 'Q12124': 13,\n",
       " 'Q12262': 6,\n",
       " 'O13540': 4,\n",
       " 'P39547': 4,\n",
       " 'O13543': 10,\n",
       " 'P15380': 19,\n",
       " 'P29055': 10,\n",
       " 'P32603': 10,\n",
       " 'Q02630': 15,\n",
       " 'O13545': 20,\n",
       " 'P37264': 20,\n",
       " 'O13547': 5,\n",
       " 'Q03761': 10,\n",
       " 'Q08271': 4,\n",
       " 'Q12380': 5,\n",
       " 'O13548': 6,\n",
       " 'Q01846': 6,\n",
       " 'O13549': 12,\n",
       " 'P16467': 12,\n",
       " 'P47821': 0,\n",
       " 'O13550': 14,\n",
       " 'P22696': 18,\n",
       " 'P33203': 18,\n",
       " 'P40070': 14,\n",
       " 'P46995': 6,\n",
       " 'P47093': 14,\n",
       " 'P47135': 16,\n",
       " 'O13553': 21,\n",
       " 'P53910': 21,\n",
       " 'O13554': 12,\n",
       " 'P38177': 12,\n",
       " 'P40465': 12,\n",
       " 'O13555': 13,\n",
       " 'P32569': 13,\n",
       " 'O13556': 18,\n",
       " 'P15938': 18,\n",
       " 'O13558': 18,\n",
       " 'P15274': 18,\n",
       " 'P32366': 22,\n",
       " 'Q12346': 4,\n",
       " 'O13559': 19,\n",
       " 'P40029': 19,\n",
       " 'Q03407': 19,\n",
       " 'O13561': 0,\n",
       " 'P38041': 0,\n",
       " 'O13562': 4,\n",
       " 'Q06598': 4,\n",
       " 'O13563': 23,\n",
       " 'P32565': 23,\n",
       " 'P38348': 23,\n",
       " 'P38886': 23,\n",
       " 'P53196': 23,\n",
       " 'O13564': 18,\n",
       " 'Q12280': 18,\n",
       " 'O13565': 19,\n",
       " 'P14908': 19,\n",
       " 'P34166': 19,\n",
       " 'O13566': 7,\n",
       " 'Q03083': 7,\n",
       " 'P23639': 23,\n",
       " 'P36224': 6,\n",
       " 'P40054': 14,\n",
       " 'O13568': 16,\n",
       " 'O13569': 16,\n",
       " 'O13573': 13,\n",
       " 'O13574': 10,\n",
       " 'P38342': 10,\n",
       " 'O13575': 18,\n",
       " 'O13576': 15,\n",
       " 'Q07990': 15,\n",
       " 'O13577': 24,\n",
       " 'P40573': 6,\n",
       " 'Q06224': 24,\n",
       " 'O13578': 25,\n",
       " 'P43539': 25,\n",
       " 'O13579': 16,\n",
       " 'O13582': 6,\n",
       " 'P25344': 6,\n",
       " 'O13583': 5,\n",
       " 'Q12300': 5,\n",
       " 'O13585': 5,\n",
       " 'P02829': 5,\n",
       " 'O13587': 3,\n",
       " 'P18899': 3,\n",
       " 'O13588': 0,\n",
       " 'Q05080': 0,\n",
       " 'O14455': 0,\n",
       " 'P38203': 14,\n",
       " 'Q06449': 0,\n",
       " 'Q12306': 11,\n",
       " 'O14467': 7,\n",
       " 'P40537': 7,\n",
       " 'O14468': 6,\n",
       " 'P11709': 6,\n",
       " 'P16649': 6,\n",
       " 'P21705': 3,\n",
       " 'P32364': 6,\n",
       " 'P32448': 6,\n",
       " 'P32457': 6,\n",
       " 'P36022': 6,\n",
       " 'P38236': 6,\n",
       " 'P46677': 6,\n",
       " 'P47124': 6,\n",
       " 'P53148': 6,\n",
       " 'P60010': 10,\n",
       " 'Q00402': 6,\n",
       " 'Q07732': 6,\n",
       " 'Q08550': 6,\n",
       " 'Q12080': 6,\n",
       " 'Q12411': 6,\n",
       " 'O60200': 7,\n",
       " 'P35200': 7,\n",
       " 'Q05776': 7,\n",
       " 'O74700': 3,\n",
       " 'P18239': 3,\n",
       " 'P36046': 3,\n",
       " 'P87108': 3,\n",
       " 'O94084': 3,\n",
       " 'P28004': 3,\n",
       " 'P38166': 22,\n",
       " 'O94085': 11,\n",
       " 'P25627': 11,\n",
       " 'P43558': 23,\n",
       " 'P43560': 18,\n",
       " 'P53427': 11,\n",
       " 'O94086': 4,\n",
       " 'P43562': 4,\n",
       " 'O94742': 23,\n",
       " 'P38009': 0,\n",
       " 'P46674': 6,\n",
       " 'P47130': 23,\n",
       " 'Q08231': 16,\n",
       " 'Q12250': 23,\n",
       " 'P00044': 3,\n",
       " 'P00431': 3,\n",
       " 'P07143': 15,\n",
       " 'P27882': 3,\n",
       " 'P38810': 19,\n",
       " 'P53823': 5,\n",
       " 'P00045': 11,\n",
       " 'P20447': 11,\n",
       " 'P23202': 3,\n",
       " 'P38881': 4,\n",
       " 'P00127': 15,\n",
       " 'P08525': 15,\n",
       " 'P32259': 13,\n",
       " 'P00128': 15,\n",
       " 'P00163': 15,\n",
       " 'P38822': 0,\n",
       " 'P39742': 4,\n",
       " 'P53168': 6,\n",
       " 'P07256': 15,\n",
       " 'P08067': 15,\n",
       " 'P00175': 26,\n",
       " 'P00330': 7,\n",
       " 'P07264': 7,\n",
       " 'P28003': 7,\n",
       " 'P28708': 19,\n",
       " 'P32492': 15,\n",
       " 'P34230': 7,\n",
       " 'P38310': 22,\n",
       " 'P39109': 7,\n",
       " 'P39715': 18,\n",
       " 'P43601': 16,\n",
       " 'P53917': 7,\n",
       " 'Q06624': 18,\n",
       " 'Q08278': 13,\n",
       " 'Q08649': 10,\n",
       " 'Q08773': 12,\n",
       " 'Q08826': 7,\n",
       " 'P00331': 18,\n",
       " 'P40318': 18,\n",
       " 'P00358': 7,\n",
       " 'Q02724': 7,\n",
       " 'Q02821': 5,\n",
       " 'Q04978': 7,\n",
       " 'Q12349': 7,\n",
       " 'P00359': 0,\n",
       " 'Q04439': 0,\n",
       " 'P00360': 5,\n",
       " 'P00401': 27,\n",
       " 'P00410': 27,\n",
       " 'P00420': 27,\n",
       " 'P04039': 27,\n",
       " 'P23833': 27,\n",
       " 'P00425': 4,\n",
       " 'P38745': 4,\n",
       " 'P38907': 14,\n",
       " 'P25354': 4,\n",
       " 'P53259': 3,\n",
       " 'Q12230': 22,\n",
       " 'P00445': 7,\n",
       " 'P23291': 7,\n",
       " 'P39009': 0,\n",
       " 'P40202': 7,\n",
       " 'P00447': 9,\n",
       " 'P23337': 19,\n",
       " 'P38238': 9,\n",
       " 'P48564': 9,\n",
       " 'Q03370': 4,\n",
       " 'P00546': 19,\n",
       " 'P07866': 14,\n",
       " 'P08153': 6,\n",
       " 'P09119': 12,\n",
       " 'P09798': 9,\n",
       " 'P09959': 19,\n",
       " 'P0CX14': 11,\n",
       " 'P0CX15': 11,\n",
       " 'P11710': 0,\n",
       " 'P11927': 19,\n",
       " 'P11978': 6,\n",
       " 'P12611': 18,\n",
       " 'P12954': 12,\n",
       " 'P13186': 0,\n",
       " 'P13365': 19,\n",
       " 'P13382': 12,\n",
       " 'P14180': 0,\n",
       " 'P14737': 19,\n",
       " 'P16522': 9,\n",
       " 'P17119': 6,\n",
       " 'P17121': 14,\n",
       " 'P20437': 19,\n",
       " 'P20438': 19,\n",
       " 'P20486': 19,\n",
       " 'P20676': 5,\n",
       " 'P21192': 19,\n",
       " 'P21268': 19,\n",
       " 'P21339': 19,\n",
       " 'P21657': 7,\n",
       " 'P21827': 19,\n",
       " 'P22204': 19,\n",
       " 'P22768': 5,\n",
       " 'P23179': 17,\n",
       " 'P23201': 6,\n",
       " 'P23748': 19,\n",
       " 'P24279': 12,\n",
       " 'P24482': 12,\n",
       " 'P24583': 6,\n",
       " 'P24814': 19,\n",
       " 'P24868': 19,\n",
       " 'P24869': 19,\n",
       " 'P24870': 19,\n",
       " 'P24871': 19,\n",
       " 'P25302': 19,\n",
       " 'P25364': 11,\n",
       " 'P25558': 19,\n",
       " 'P25579': 19,\n",
       " 'P26309': 19,\n",
       " 'P26798': 24,\n",
       " 'P27895': 6,\n",
       " 'P28006': 0,\n",
       " 'P28743': 6,\n",
       " 'P29366': 0,\n",
       " 'P30283': 0,\n",
       " 'P31111': 6,\n",
       " 'P31380': 14,\n",
       " 'P32325': 12,\n",
       " 'P32328': 19,\n",
       " 'P32334': 19,\n",
       " 'P32356': 19,\n",
       " 'P32380': 6,\n",
       " 'P32447': 10,\n",
       " 'P32526': 0,\n",
       " 'P32562': 6,\n",
       " 'P32567': 19,\n",
       " 'P32786': 19,\n",
       " 'P32797': 12,\n",
       " 'P32801': 5,\n",
       " 'P32833': 12,\n",
       " 'P32873': 0,\n",
       " 'P32900': 0,\n",
       " 'P32943': 19,\n",
       " 'P32944': 6,\n",
       " 'P33306': 22,\n",
       " 'P33332': 0,\n",
       " 'P34161': 16,\n",
       " 'P34233': 19,\n",
       " 'P34241': 19,\n",
       " 'P34252': 12,\n",
       " 'P36005': 19,\n",
       " 'P36093': 11,\n",
       " 'P36094': 6,\n",
       " 'P36157': 11,\n",
       " 'P36158': 19,\n",
       " 'P36165': 18,\n",
       " 'P36166': 14,\n",
       " 'P36167': 19,\n",
       " 'P38042': 9,\n",
       " 'P38257': 0,\n",
       " 'P38261': 6,\n",
       " 'P38277': 5,\n",
       " 'P38634': 19,\n",
       " 'P38717': 19,\n",
       " 'P38721': 19,\n",
       " 'P38735': 0,\n",
       " 'P38826': 12,\n",
       " 'P38853': 6,\n",
       " 'P38854': 6,\n",
       " 'P38859': 12,\n",
       " 'P38903': 0,\n",
       " 'P38909': 10,\n",
       " 'P38928': 4,\n",
       " 'P38990': 11,\n",
       " 'P38991': 6,\n",
       " 'P39083': 6,\n",
       " 'P39520': 11,\n",
       " 'P39685': 4,\n",
       " 'P39705': 5,\n",
       " 'P39732': 0,\n",
       " 'P39734': 6,\n",
       " 'P39980': 19,\n",
       " 'P40020': 0,\n",
       " 'P40028': 19,\n",
       " 'P40038': 19,\n",
       " 'P40095': 0,\n",
       " 'P40186': 19,\n",
       " 'P40316': 19,\n",
       " 'P40340': 6,\n",
       " 'P40473': 19,\n",
       " 'P40480': 6,\n",
       " 'P40484': 19,\n",
       " 'P40489': 19,\n",
       " 'P41697': 6,\n",
       " 'P41813': 19,\n",
       " 'P41832': 6,\n",
       " 'P41834': 6,\n",
       " 'P41895': 9,\n",
       " 'P42839': 4,\n",
       " 'P42845': 19,\n",
       " 'P42943': 0,\n",
       " 'P43568': 5,\n",
       " 'P43605': 6,\n",
       " 'P43618': 6,\n",
       " 'P46675': 6,\n",
       " 'P47029': 19,\n",
       " 'P47039': 5,\n",
       " 'P47074': 19,\n",
       " 'P47104': 22,\n",
       " 'P47114': 19,\n",
       " 'P47116': 5,\n",
       " 'P47129': 0,\n",
       " 'P47136': 19,\n",
       " 'P50078': 0,\n",
       " 'P50090': 6,\n",
       " 'P50105': 10,\n",
       " 'P50275': 6,\n",
       " 'P52919': 6,\n",
       " 'P53071': 19,\n",
       " 'P53086': 7,\n",
       " 'P53129': 3,\n",
       " 'P53159': 6,\n",
       " 'P53197': 19,\n",
       " 'P53222': 24,\n",
       " 'P53551': 11,\n",
       " 'P53739': 19,\n",
       " 'P53819': 10,\n",
       " 'P53836': 19,\n",
       " 'P53894': 19,\n",
       " 'P53947': 0,\n",
       " 'P53958': 24,\n",
       " 'P54784': 12,\n",
       " 'P54786': 0,\n",
       " 'P54867': 19,\n",
       " 'Q00416': 6,\n",
       " 'Q00684': 19,\n",
       " 'Q00772': 19,\n",
       " 'Q01389': 0,\n",
       " 'Q01684': 0,\n",
       " 'Q02455': 11,\n",
       " 'Q02606': 19,\n",
       " 'Q02866': 5,\n",
       " 'Q03208': 19,\n",
       " 'Q03231': 19,\n",
       " 'Q03254': 6,\n",
       " 'Q03707': 5,\n",
       " 'Q03834': 12,\n",
       " 'Q03898': 6,\n",
       " 'Q04087': 6,\n",
       " 'Q04116': 19,\n",
       " 'Q04383': 22,\n",
       " 'Q04930': 19,\n",
       " 'Q05518': 7,\n",
       " 'Q05672': 5,\n",
       " 'Q05812': 22,\n",
       " 'Q05854': 19,\n",
       " 'Q06001': 6,\n",
       " 'Q06032': 19,\n",
       " 'Q06053': 9,\n",
       " 'Q06168': 10,\n",
       " 'Q06266': 15,\n",
       " 'Q06315': 19,\n",
       " 'Q06324': 6,\n",
       " 'Q06407': 19,\n",
       " 'Q06412': 22,\n",
       " 'Q06604': 0,\n",
       " 'Q06616': 6,\n",
       " 'Q06648': 0,\n",
       " 'Q07084': 19,\n",
       " 'Q07528': 6,\n",
       " 'Q07980': 15,\n",
       " 'Q08206': 19,\n",
       " 'Q08229': 0,\n",
       " 'Q08471': 19,\n",
       " 'Q08581': 6,\n",
       " 'Q08887': 19,\n",
       " 'Q08949': 13,\n",
       " 'Q08981': 19,\n",
       " 'Q12043': 5,\n",
       " 'Q12048': 19,\n",
       " 'Q12057': 22,\n",
       " 'Q12066': 16,\n",
       " 'Q12071': 6,\n",
       " 'Q12088': 19,\n",
       " 'Q12100': 19,\n",
       " 'Q12107': 9,\n",
       " 'Q12149': 17,\n",
       " 'Q12236': 22,\n",
       " 'Q12263': 6,\n",
       " 'Q12267': 6,\n",
       " 'Q12365': 6,\n",
       " 'Q12369': 19,\n",
       " 'Q12398': 5,\n",
       " 'Q12416': 19,\n",
       " 'Q12495': 6,\n",
       " 'Q12507': 16,\n",
       " 'Q12675': 22,\n",
       " 'Q12734': 19,\n",
       " 'P00549': 5,\n",
       " 'P06244': 19,\n",
       " 'Q12056': 5,\n",
       " 'P00560': 7,\n",
       " 'P0CE68': 7,\n",
       " 'P0CE69': 7,\n",
       " 'P21264': 7,\n",
       " 'P34162': 13,\n",
       " 'Q12415': 7,\n",
       " 'P00572': 5,\n",
       " 'P32502': 5,\n",
       " 'P00635': 13,\n",
       " 'P36173': 4,\n",
       " 'Q03630': 13,\n",
       " 'P00724': 16,\n",
       " 'P53295': 16,\n",
       " 'Q12154': 16,\n",
       " 'P00729': 23,\n",
       " 'P14306': 23,\n",
       " 'P25694': 23,\n",
       " 'P32915': 4,\n",
       " 'P38307': 23,\n",
       " 'Q05787': 23,\n",
       " 'Q08109': 23,\n",
       " 'P00812': 0,\n",
       " 'P43580': 0,\n",
       " 'P53281': 0,\n",
       " 'Q06142': 5,\n",
       " 'P00815': 28,\n",
       " 'P53233': 28,\n",
       " 'P00817': 18,\n",
       " 'P06787': 18,\n",
       " 'Q08409': 18,\n",
       " 'P00830': 16,\n",
       " 'P00854': 16,\n",
       " 'P00856': 16,\n",
       " 'P05626': 16,\n",
       " 'P07251': 16,\n",
       " 'P09457': 16,\n",
       " 'P21306': 16,\n",
       " 'P30902': 6,\n",
       " 'P32453': 4,\n",
       " 'P38077': 16,\n",
       " 'P38347': 16,\n",
       " 'P40892': 5,\n",
       " 'P81450': 16,\n",
       " 'Q06208': 16,\n",
       " 'Q06405': 16,\n",
       " 'Q12165': 16,\n",
       " 'P25611': 7,\n",
       " 'P00890': 13,\n",
       " 'P00899': 5,\n",
       " 'P00937': 5,\n",
       " 'P38328': 0,\n",
       " 'P41811': 22,\n",
       " 'P47120': 5,\n",
       " 'Q99312': 5,\n",
       " 'P00912': 3,\n",
       " 'P19146': 22,\n",
       " 'P00924': 7,\n",
       " 'P53732': 7,\n",
       " 'P00925': 18,\n",
       " 'P40498': 18,\n",
       " 'P41909': 7,\n",
       " 'Q06148': 11,\n",
       " 'Q08234': 4,\n",
       " 'Q6Q5F3': 12,\n",
       " 'P00927': 0,\n",
       " 'P10849': 0,\n",
       " 'P25651': 0,\n",
       " 'P32337': 5,\n",
       " 'P32776': 13,\n",
       " 'P35729': 28,\n",
       " 'P38340': 5,\n",
       " 'P47068': 0,\n",
       " 'P80667': 0,\n",
       " 'Q06338': 5,\n",
       " 'Q08907': 0,\n",
       " 'Q12163': 0,\n",
       " 'Q99189': 5,\n",
       " 'P00931': 7,\n",
       " 'P32645': 9,\n",
       " 'P00942': 7,\n",
       " 'P14772': 7,\n",
       " 'P00950': 0,\n",
       " 'P33334': 14,\n",
       " 'P53076': 18,\n",
       " 'P00958': 18,\n",
       " 'P46672': 7,\n",
       " 'P01094': 18,\n",
       " 'P07267': 18,\n",
       " 'P01097': 6,\n",
       " 'P12753': 6,\n",
       " 'P31376': 6,\n",
       " 'P34237': 6,\n",
       " 'P53253': 6,\n",
       " 'P53930': 6,\n",
       " 'Q06675': 24,\n",
       " 'P01098': 6,\n",
       " 'P35727': 6,\n",
       " 'P40368': 6,\n",
       " 'P41901': 6,\n",
       " 'Q04477': 6,\n",
       " 'Q07508': 6,\n",
       " 'Q12514': 14,\n",
       " 'P01119': 5,\n",
       " 'P34760': 5,\n",
       " 'P39010': 22,\n",
       " 'Q06214': 5,\n",
       " 'P01120': 22,\n",
       " 'P32572': 3,\n",
       " 'P33302': 22,\n",
       " 'P38165': 6,\n",
       " 'P43588': 23,\n",
       " 'P53049': 22,\n",
       " 'Q02895': 5,\n",
       " 'P01123': 3,\n",
       " 'P11076': 22,\n",
       " 'P20133': 3,\n",
       " 'P25385': 6,\n",
       " 'P27999': 9,\n",
       " 'P32601': 3,\n",
       " 'P32854': 3,\n",
       " 'P32864': 3,\n",
       " 'P38130': 0,\n",
       " 'P39958': 3,\n",
       " 'P40093': 19,\n",
       " 'P53039': 3,\n",
       " 'P53093': 3,\n",
       " 'P53108': 3,\n",
       " 'P53845': 3,\n",
       " 'P54783': 16,\n",
       " 'Q01590': 6,\n",
       " 'Q08484': 3,\n",
       " 'Q12270': 22,\n",
       " 'Q12383': 3,\n",
       " 'Q12527': 6,\n",
       " 'P02293': 10,\n",
       " 'P04911': 10,\n",
       " 'P38431': 18,\n",
       " 'P53874': 11,\n",
       " 'Q07457': 6,\n",
       " 'Q12373': 10,\n",
       " 'P02294': 5,\n",
       " 'P06104': 12,\n",
       " 'P0CY06': 5,\n",
       " 'P25293': 5,\n",
       " 'P02309': 10,\n",
       " 'P06701': 12,\n",
       " 'P15790': 11,\n",
       " 'P35817': 6,\n",
       " 'P36012': 10,\n",
       " 'P38074': 11,\n",
       " 'P38890': 19,\n",
       " 'P43572': 10,\n",
       " 'P53686': 10,\n",
       " 'P61830': 10,\n",
       " 'Q03330': 10,\n",
       " 'Q06205': 11,\n",
       " 'Q12161': 10,\n",
       " 'Q12341': 10,\n",
       " 'Q12692': 10,\n",
       " 'P02400': 12,\n",
       " 'P05317': 12,\n",
       " 'P05318': 12,\n",
       " 'P10622': 12,\n",
       " 'P32790': 0,\n",
       " 'P38067': 12,\n",
       " 'P02407': 11,\n",
       " 'P02557': 6,\n",
       " 'P09733': 6,\n",
       " 'P48606': 6,\n",
       " 'Q02785': 22,\n",
       " 'Q04004': 24,\n",
       " 'P04076': 5,\n",
       " 'P04802': 0,\n",
       " 'P04817': 4,\n",
       " 'P06101': 5,\n",
       " 'P07248': 7,\n",
       " 'P07263': 10,\n",
       " 'P07275': 5,\n",
       " 'P07991': 5,\n",
       " 'P0CD99': 4,\n",
       " 'P0CE00': 4,\n",
       " 'P0CE41': 4,\n",
       " 'P0CS82': 5,\n",
       " 'P0CX12': 4,\n",
       " 'P0CX13': 4,\n",
       " 'P0CX49': 13,\n",
       " 'P0CX50': 13,\n",
       " 'P14681': 5,\n",
       " 'P15365': 4,\n",
       " 'P15442': 7,\n",
       " 'P15625': 28,\n",
       " 'P15705': 5,\n",
       " 'P17536': 5,\n",
       " 'P19882': 5,\n",
       " 'P21147': 4,\n",
       " 'P22140': 4,\n",
       " 'P22203': 22,\n",
       " 'P23561': 5,\n",
       " 'P25294': 7,\n",
       " 'P25491': 5,\n",
       " 'P25584': 16,\n",
       " 'P25607': 4,\n",
       " 'P25623': 22,\n",
       " 'P25628': 6,\n",
       " 'P25638': 5,\n",
       " 'P28496': 4,\n",
       " 'P28707': 7,\n",
       " 'P29547': 7,\n",
       " 'P31381': 4,\n",
       " 'P32419': 18,\n",
       " 'P32460': 5,\n",
       " 'P32465': 22,\n",
       " 'P32468': 6,\n",
       " 'P32485': 19,\n",
       " 'P32487': 22,\n",
       " 'P32589': 7,\n",
       " 'P32621': 4,\n",
       " 'P32861': 18,\n",
       " 'P32939': 3,\n",
       " 'P33200': 0,\n",
       " 'P33296': 18,\n",
       " 'P33313': 5,\n",
       " 'P35497': 5,\n",
       " 'P36019': 3,\n",
       " 'P36023': 5,\n",
       " 'P36029': 4,\n",
       " 'P36088': 7,\n",
       " 'P36125': 0,\n",
       " 'P36137': 5,\n",
       " 'P36148': 22,\n",
       " 'P38075': 5,\n",
       " 'P38090': 0,\n",
       " 'P38270': 6,\n",
       " 'P38272': 15,\n",
       " 'P38318': 9,\n",
       " 'P38323': 10,\n",
       " 'P38349': 23,\n",
       " 'P38356': 4,\n",
       " 'P38429': 19,\n",
       " 'P38555': 3,\n",
       " 'P38637': 5,\n",
       " 'P38695': 22,\n",
       " 'P38720': 18,\n",
       " 'P38734': 7,\n",
       " 'P38768': 10,\n",
       " 'P38770': 28,\n",
       " 'P38825': 7,\n",
       " 'P38910': 5,\n",
       " 'P38962': 5,\n",
       " 'P39078': 0,\n",
       " 'P39721': 5,\n",
       " 'P39727': 4,\n",
       " 'P40073': 0,\n",
       " 'P40074': 15,\n",
       " 'P40169': 4,\n",
       " 'P40458': 13,\n",
       " 'P40475': 4,\n",
       " 'P40531': 5,\n",
       " 'P40549': 5,\n",
       " 'P40558': 19,\n",
       " 'P40586': 5,\n",
       " 'P41808': 5,\n",
       " 'P41815': 4,\n",
       " 'P41896': 9,\n",
       " 'P42836': 22,\n",
       " 'P43581': 22,\n",
       " 'P43682': 4,\n",
       " 'P46956': 4,\n",
       " 'P46970': 19,\n",
       " 'P46993': 15,\n",
       " 'P47023': 6,\n",
       " 'P47103': 5,\n",
       " 'P47111': 22,\n",
       " 'P47119': 14,\n",
       " 'P47123': 5,\n",
       " 'P47166': 6,\n",
       " 'P48837': 6,\n",
       " 'P49334': 16,\n",
       " 'P50276': 22,\n",
       " 'P50945': 16,\n",
       " 'P51534': 0,\n",
       " 'P52489': 19,\n",
       " 'P53043': 7,\n",
       " 'P53048': 4,\n",
       " 'P53344': 4,\n",
       " 'P53394': 4,\n",
       " 'P53629': 4,\n",
       " 'P53631': 14,\n",
       " 'P53691': 7,\n",
       " 'P53834': 7,\n",
       " 'P53918': 4,\n",
       " 'P53927': 11,\n",
       " 'P53943': 5,\n",
       " 'P89113': 10,\n",
       " 'Q02196': 5,\n",
       " 'Q02784': 0,\n",
       " 'Q02981': 5,\n",
       " 'Q03102': 5,\n",
       " 'Q03175': 7,\n",
       " 'Q03795': 18,\n",
       " 'Q03818': 5,\n",
       " 'Q04031': 6,\n",
       " 'Q04344': 5,\n",
       " 'Q04658': 5,\n",
       " 'Q05637': 19,\n",
       " 'Q05871': 16,\n",
       " 'Q06058': 19,\n",
       " 'Q06108': 5,\n",
       " 'Q06494': 5,\n",
       " 'Q06497': 4,\n",
       " 'Q06523': 10,\n",
       " 'Q06676': 7,\n",
       " 'Q06892': 0,\n",
       " 'Q07748': 18,\n",
       " 'Q07786': 5,\n",
       " 'Q07788': 5,\n",
       " 'Q07986': 13,\n",
       " 'Q07993': 5,\n",
       " 'Q08144': 4,\n",
       " 'Q08176': 7,\n",
       " 'Q08227': 4,\n",
       " 'Q08280': 22,\n",
       " 'Q08446': 19,\n",
       " 'Q08926': 4,\n",
       " 'Q08954': 5,\n",
       " 'Q08974': 10,\n",
       " 'Q08980': 4,\n",
       " 'Q12122': 18,\n",
       " 'Q12206': 5,\n",
       " 'Q12274': 16,\n",
       " 'Q12301': 5,\n",
       " 'Q12329': 16,\n",
       " 'Q12407': 4,\n",
       " 'Q12461': 0,\n",
       " 'Q12462': 16,\n",
       " 'Q12489': 0,\n",
       " 'Q12498': 0,\n",
       " 'Q12516': 5,\n",
       " 'Q99190': 4,\n",
       " 'Q99288': 5,\n",
       " 'Q99393': 5,\n",
       " 'P02992': 24,\n",
       " 'Q03050': 24,\n",
       " 'P02994': 7,\n",
       " 'P06782': 0,\n",
       " 'P16521': 7,\n",
       " 'P32471': 7,\n",
       " 'P32581': 0,\n",
       " 'P07834': 19,\n",
       " 'P17157': 19,\n",
       " 'P19659': 13,\n",
       " 'P22082': 10,\n",
       " 'P38207': 12,\n",
       " 'P38811': 10,\n",
       " 'P39013': 6,\n",
       " 'Q02336': 10,\n",
       " 'Q03081': 0,\n",
       " 'Q12377': 23,\n",
       " 'P03870': 29,\n",
       " 'P03879': 30,\n",
       " 'P11325': 30,\n",
       " 'P26637': 30,\n",
       " 'P03882': 31,\n",
       " 'P03962': 32,\n",
       " 'P04037': 17,\n",
       " 'P21954': 17,\n",
       " 'P32796': 16,\n",
       " 'P38274': 0,\n",
       " 'Q02793': 17,\n",
       " 'P43592': 6,\n",
       " 'P04046': 16,\n",
       " 'P07286': 4,\n",
       " 'P06242': 13,\n",
       " 'P07273': 9,\n",
       " 'P08518': 9,\n",
       " 'P16370': 9,\n",
       " 'P20433': 9,\n",
       " 'P20434': 9,\n",
       " 'P20435': 9,\n",
       " 'P20436': 9,\n",
       " 'P22139': 9,\n",
       " 'P23293': 11,\n",
       " 'P23615': 14,\n",
       " 'P27692': 11,\n",
       " 'P32585': 13,\n",
       " 'P34087': 9,\n",
       " 'P36145': 13,\n",
       " 'P38782': 13,\n",
       " 'P38902': 9,\n",
       " 'P39073': 13,\n",
       " 'P39081': 24,\n",
       " 'P40084': 9,\n",
       " 'P53064': 11,\n",
       " 'P53538': 5,\n",
       " 'P53617': 13,\n",
       " 'P53842': 9,\n",
       " 'Q01477': 9,\n",
       " 'Q03957': 18,\n",
       " 'Q05543': 6,\n",
       " 'Q06632': 24,\n",
       " 'Q06697': 11,\n",
       " 'Q06706': 9,\n",
       " 'Q06834': 9,\n",
       " 'P04051': 9,\n",
       " 'P07703': 9,\n",
       " 'P15891': 0,\n",
       " 'P22276': 9,\n",
       " 'P32349': 9,\n",
       " 'P32910': 9,\n",
       " 'P35718': 9,\n",
       " 'P41910': 19,\n",
       " 'P04147': 14,\n",
       " 'P05453': 0,\n",
       " 'P07260': 14,\n",
       " 'P30822': 14,\n",
       " 'P36102': 14,\n",
       " 'P39935': 14,\n",
       " 'P39936': 14,\n",
       " 'P40561': 14,\n",
       " 'P53297': 14,\n",
       " 'Q99257': 5,\n",
       " 'P04161': 13,\n",
       " 'P25337': 13,\n",
       " 'P36108': 24,\n",
       " 'Q12343': 13,\n",
       " 'P04173': 19,\n",
       " 'P04385': 13,\n",
       " 'P04387': 13,\n",
       " 'P04386': 13,\n",
       " 'P13393': 10,\n",
       " 'P53549': 23,\n",
       " 'Q02516': 0,\n",
       " 'P07269': 0,\n",
       " 'P13045': 13,\n",
       " 'P25046': 13,\n",
       " 'P25367': 5,\n",
       " 'P25502': 19,\n",
       " 'P32607': 13,\n",
       " 'P33308': 13,\n",
       " 'P36000': 24,\n",
       " 'P36003': 3,\n",
       " 'P38709': 13,\n",
       " 'P39959': 19,\n",
       " 'P40959': 22,\n",
       " 'P41913': 0,\n",
       " 'P47822': 6,\n",
       " 'P48235': 13,\n",
       " 'P50102': 10,\n",
       " 'P50875': 10,\n",
       " 'Q00723': 14,\n",
       " 'Q03067': 10,\n",
       " 'Q05610': 13,\n",
       " 'Q05785': 6,\n",
       " 'Q08601': 0,\n",
       " 'Q08831': 18,\n",
       " 'Q12493': 6,\n",
       " 'P04397': 24,\n",
       " 'P38700': 24,\n",
       " 'Q08293': 19,\n",
       " 'P04449': 11,\n",
       " 'P0CX41': 11,\n",
       " 'Q12522': 11,\n",
       " 'P04456': 7,\n",
       " 'Q02642': 7,\n",
       " 'P04650': 5,\n",
       " 'P38615': 5,\n",
       " 'P04710': 14,\n",
       " 'P47017': 14,\n",
       " 'P53744': 14,\n",
       " 'Q07807': 14,\n",
       " 'P04786': 6,\n",
       " 'P0CY08': 28,\n",
       " 'P0CY12': 28,\n",
       " 'P21651': 6,\n",
       " 'P32489': 6,\n",
       " 'P50946': 24,\n",
       " 'Q05024': 7,\n",
       " 'Q12255': 6,\n",
       " 'P04801': 18,\n",
       " 'P38781': 16,\n",
       " 'Q08741': 0,\n",
       " 'P04803': 16,\n",
       " 'Q12420': 16,\n",
       " 'P04806': 14,\n",
       " 'P40434': 14,\n",
       " 'Q3E7X8': 14,\n",
       " 'P04807': 14,\n",
       " 'P27705': 0,\n",
       " 'P14906': 4,\n",
       " 'P16661': 4,\n",
       " ...}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw the graph\n",
    "pos = nx.spring_layout(G) # spring_layout\n",
    "# color the nodes according to their partition\n",
    "cmap = cm.get_cmap('viridis', max(partition.values()) + 1)\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, partition.keys(), node_size=40,\n",
    "                       cmap=cmap, node_color=list(partition.values()))\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(set(partition.values())) # partitioned into 9 communities.... why? \n",
    "#len(partition.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Graph' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-870a2f23559a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# how to plot the frequency of values...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Graph' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "partition.values()\n",
    "\n",
    "# how to plot the frequency of values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'A0A023PYF7': 0,\n",
       "  'P39743': 0,\n",
       "  'A0A250W8A7': 1,\n",
       "  'A0A250WL92': 2,\n",
       "  'A2P2R3': 0,\n",
       "  'P04821': 0,\n",
       "  'P38753': 0,\n",
       "  'D6VPM8': 3,\n",
       "  'P38723': 4,\n",
       "  'Q12328': 3,\n",
       "  'D6VTK4': 3,\n",
       "  'P08539': 5,\n",
       "  'P18851': 6,\n",
       "  'P32435': 3,\n",
       "  'P32793': 0,\n",
       "  'P32844': 3,\n",
       "  'P53285': 3,\n",
       "  'Q08646': 3,\n",
       "  'Q08929': 4,\n",
       "  'D6W196': 7,\n",
       "  'P29704': 7,\n",
       "  'P53983': 4,\n",
       "  'E9P8D2': 8,\n",
       "  'O13297': 9,\n",
       "  'P04050': 9,\n",
       "  'Q01159': 9,\n",
       "  'O13329': 0,\n",
       "  'P06700': 10,\n",
       "  'P06843': 11,\n",
       "  'P17123': 0,\n",
       "  'P22216': 12,\n",
       "  'P32605': 13,\n",
       "  'P32902': 6,\n",
       "  'P38633': 13,\n",
       "  'P38987': 5,\n",
       "  'P40089': 14,\n",
       "  'P47035': 9,\n",
       "  'Q00916': 0,\n",
       "  'Q02208': 0,\n",
       "  'Q03776': 0,\n",
       "  'Q12072': 0,\n",
       "  'Q12457': 11,\n",
       "  'O13512': 14,\n",
       "  'O13567': 14,\n",
       "  'O13517': 15,\n",
       "  'P40971': 15,\n",
       "  'O13518': 16,\n",
       "  'P32841': 16,\n",
       "  'O13519': 3,\n",
       "  'P19657': 3,\n",
       "  'P38260': 3,\n",
       "  'O13525': 10,\n",
       "  'P27680': 10,\n",
       "  'Q05779': 10,\n",
       "  'O13527': 14,\n",
       "  'P53550': 14,\n",
       "  'O13530': 5,\n",
       "  'P21825': 4,\n",
       "  'P39534': 5,\n",
       "  'O13531': 17,\n",
       "  'P39940': 17,\n",
       "  'P40568': 6,\n",
       "  'P43582': 17,\n",
       "  'Q02574': 13,\n",
       "  'Q06525': 17,\n",
       "  'O13532': 6,\n",
       "  'P47128': 6,\n",
       "  'O13535': 0,\n",
       "  'P36006': 0,\n",
       "  'O13537': 10,\n",
       "  'P03069': 10,\n",
       "  'P53541': 10,\n",
       "  'O13539': 6,\n",
       "  'P33441': 6,\n",
       "  'P40014': 6,\n",
       "  'P47076': 9,\n",
       "  'P53552': 6,\n",
       "  'P53959': 6,\n",
       "  'Q06410': 6,\n",
       "  'Q08118': 0,\n",
       "  'Q12124': 13,\n",
       "  'Q12262': 6,\n",
       "  'O13540': 4,\n",
       "  'P39547': 4,\n",
       "  'O13543': 18,\n",
       "  'P15380': 19,\n",
       "  'P29055': 10,\n",
       "  'P32603': 18,\n",
       "  'Q02630': 18,\n",
       "  'O13545': 20,\n",
       "  'P37264': 20,\n",
       "  'O13547': 10,\n",
       "  'Q03761': 10,\n",
       "  'Q08271': 4,\n",
       "  'Q12380': 5,\n",
       "  'O13548': 6,\n",
       "  'Q01846': 6,\n",
       "  'O13549': 12,\n",
       "  'P16467': 12,\n",
       "  'P47821': 0,\n",
       "  'O13550': 17,\n",
       "  'P22696': 17,\n",
       "  'P33203': 17,\n",
       "  'P40070': 14,\n",
       "  'P46995': 17,\n",
       "  'P47093': 14,\n",
       "  'P47135': 15,\n",
       "  'O13553': 21,\n",
       "  'P53910': 21,\n",
       "  'O13554': 12,\n",
       "  'P38177': 12,\n",
       "  'P40465': 12,\n",
       "  'O13555': 13,\n",
       "  'P32569': 13,\n",
       "  'O13556': 17,\n",
       "  'P15938': 17,\n",
       "  'O13558': 17,\n",
       "  'P15274': 17,\n",
       "  'P32366': 22,\n",
       "  'Q12346': 4,\n",
       "  'O13559': 7,\n",
       "  'P40029': 7,\n",
       "  'Q03407': 19,\n",
       "  'O13561': 0,\n",
       "  'P38041': 0,\n",
       "  'O13562': 4,\n",
       "  'Q06598': 4,\n",
       "  'O13563': 23,\n",
       "  'P32565': 23,\n",
       "  'P38348': 23,\n",
       "  'P38886': 23,\n",
       "  'P53196': 23,\n",
       "  'O13564': 17,\n",
       "  'Q12280': 17,\n",
       "  'O13565': 19,\n",
       "  'P14908': 19,\n",
       "  'P34166': 19,\n",
       "  'O13566': 7,\n",
       "  'Q03083': 7,\n",
       "  'P23639': 23,\n",
       "  'P36224': 6,\n",
       "  'P40054': 14,\n",
       "  'O13568': 15,\n",
       "  'O13569': 15,\n",
       "  'O13573': 13,\n",
       "  'O13574': 10,\n",
       "  'P38342': 10,\n",
       "  'O13575': 17,\n",
       "  'O13576': 18,\n",
       "  'Q07990': 18,\n",
       "  'O13577': 24,\n",
       "  'P40573': 6,\n",
       "  'Q06224': 24,\n",
       "  'O13578': 25,\n",
       "  'P43539': 25,\n",
       "  'O13579': 15,\n",
       "  'O13582': 6,\n",
       "  'P25344': 6,\n",
       "  'O13583': 5,\n",
       "  'Q12300': 5,\n",
       "  'O13585': 5,\n",
       "  'P02829': 5,\n",
       "  'O13587': 3,\n",
       "  'P18899': 3,\n",
       "  'O13588': 0,\n",
       "  'Q05080': 0,\n",
       "  'O14455': 0,\n",
       "  'P38203': 14,\n",
       "  'Q06449': 0,\n",
       "  'Q12306': 11,\n",
       "  'O14467': 7,\n",
       "  'P40537': 7,\n",
       "  'O14468': 6,\n",
       "  'P11709': 6,\n",
       "  'P16649': 6,\n",
       "  'P21705': 3,\n",
       "  'P32364': 6,\n",
       "  'P32448': 6,\n",
       "  'P32457': 6,\n",
       "  'P36022': 6,\n",
       "  'P38236': 6,\n",
       "  'P46677': 6,\n",
       "  'P47124': 6,\n",
       "  'P53148': 6,\n",
       "  'P60010': 10,\n",
       "  'Q00402': 6,\n",
       "  'Q07732': 6,\n",
       "  'Q08550': 6,\n",
       "  'Q12080': 6,\n",
       "  'Q12411': 6,\n",
       "  'O60200': 7,\n",
       "  'P35200': 7,\n",
       "  'Q05776': 7,\n",
       "  'O74700': 3,\n",
       "  'P18239': 3,\n",
       "  'P36046': 3,\n",
       "  'P87108': 3,\n",
       "  'O94084': 3,\n",
       "  'P28004': 3,\n",
       "  'P38166': 22,\n",
       "  'O94085': 11,\n",
       "  'P25627': 11,\n",
       "  'P43558': 23,\n",
       "  'P43560': 12,\n",
       "  'P53427': 11,\n",
       "  'O94086': 4,\n",
       "  'P43562': 4,\n",
       "  'O94742': 23,\n",
       "  'P38009': 0,\n",
       "  'P46674': 6,\n",
       "  'P47130': 23,\n",
       "  'Q08231': 23,\n",
       "  'Q12250': 23,\n",
       "  'P00044': 3,\n",
       "  'P00431': 3,\n",
       "  'P07143': 18,\n",
       "  'P27882': 3,\n",
       "  'P38810': 19,\n",
       "  'P53823': 5,\n",
       "  'P00045': 3,\n",
       "  'P20447': 11,\n",
       "  'P23202': 3,\n",
       "  'P38881': 4,\n",
       "  'P00127': 18,\n",
       "  'P08525': 18,\n",
       "  'P32259': 13,\n",
       "  'P00128': 18,\n",
       "  'P00163': 18,\n",
       "  'P38822': 0,\n",
       "  'P39742': 4,\n",
       "  'P53168': 6,\n",
       "  'P07256': 18,\n",
       "  'P08067': 18,\n",
       "  'P00175': 26,\n",
       "  'P00330': 7,\n",
       "  'P07264': 7,\n",
       "  'P28003': 7,\n",
       "  'P28708': 19,\n",
       "  'P32492': 18,\n",
       "  'P34230': 7,\n",
       "  'P38310': 22,\n",
       "  'P39109': 7,\n",
       "  'P39715': 7,\n",
       "  'P43601': 15,\n",
       "  'P53917': 0,\n",
       "  'Q06624': 17,\n",
       "  'Q08278': 13,\n",
       "  'Q08649': 10,\n",
       "  'Q08773': 12,\n",
       "  'Q08826': 22,\n",
       "  'P00331': 17,\n",
       "  'P40318': 17,\n",
       "  'P00358': 7,\n",
       "  'Q02724': 7,\n",
       "  'Q02821': 5,\n",
       "  'Q04978': 7,\n",
       "  'Q12349': 7,\n",
       "  'P00359': 0,\n",
       "  'Q04439': 0,\n",
       "  'P00360': 5,\n",
       "  'P00401': 27,\n",
       "  'P00410': 27,\n",
       "  'P00420': 27,\n",
       "  'P04039': 27,\n",
       "  'P23833': 27,\n",
       "  'P00425': 4,\n",
       "  'P38745': 4,\n",
       "  'P38907': 14,\n",
       "  'P25354': 4,\n",
       "  'P53259': 3,\n",
       "  'Q12230': 22,\n",
       "  'P00445': 7,\n",
       "  'P23291': 7,\n",
       "  'P39009': 12,\n",
       "  'P40202': 15,\n",
       "  'P00447': 9,\n",
       "  'P23337': 19,\n",
       "  'P38238': 9,\n",
       "  'P48564': 9,\n",
       "  'Q03370': 4,\n",
       "  'P00546': 19,\n",
       "  'P07866': 19,\n",
       "  'P08153': 6,\n",
       "  'P09119': 12,\n",
       "  'P09798': 9,\n",
       "  'P09959': 19,\n",
       "  'P0CX14': 11,\n",
       "  'P0CX15': 11,\n",
       "  'P11710': 0,\n",
       "  'P11927': 19,\n",
       "  'P11978': 6,\n",
       "  'P12611': 17,\n",
       "  'P12954': 12,\n",
       "  'P13186': 19,\n",
       "  'P13365': 19,\n",
       "  'P13382': 12,\n",
       "  'P14180': 0,\n",
       "  'P14737': 12,\n",
       "  'P16522': 9,\n",
       "  'P17119': 6,\n",
       "  'P17121': 14,\n",
       "  'P20437': 19,\n",
       "  'P20438': 19,\n",
       "  'P20486': 19,\n",
       "  'P20676': 5,\n",
       "  'P21192': 19,\n",
       "  'P21268': 19,\n",
       "  'P21339': 19,\n",
       "  'P21657': 9,\n",
       "  'P21827': 19,\n",
       "  'P22204': 19,\n",
       "  'P22768': 19,\n",
       "  'P23179': 16,\n",
       "  'P23201': 6,\n",
       "  'P23748': 19,\n",
       "  'P24279': 12,\n",
       "  'P24482': 12,\n",
       "  'P24583': 6,\n",
       "  'P24814': 19,\n",
       "  'P24868': 19,\n",
       "  'P24869': 19,\n",
       "  'P24870': 19,\n",
       "  'P24871': 19,\n",
       "  'P25302': 19,\n",
       "  'P25364': 3,\n",
       "  'P25558': 19,\n",
       "  'P25579': 19,\n",
       "  'P26309': 19,\n",
       "  'P26798': 24,\n",
       "  'P27895': 6,\n",
       "  'P28006': 0,\n",
       "  'P28743': 6,\n",
       "  'P29366': 0,\n",
       "  'P30283': 19,\n",
       "  'P31111': 6,\n",
       "  'P31380': 19,\n",
       "  'P32325': 12,\n",
       "  'P32328': 19,\n",
       "  'P32334': 19,\n",
       "  'P32356': 19,\n",
       "  'P32380': 6,\n",
       "  'P32447': 10,\n",
       "  'P32526': 6,\n",
       "  'P32562': 6,\n",
       "  'P32567': 19,\n",
       "  'P32786': 19,\n",
       "  'P32797': 12,\n",
       "  'P32801': 19,\n",
       "  'P32833': 12,\n",
       "  'P32873': 0,\n",
       "  'P32900': 0,\n",
       "  'P32943': 19,\n",
       "  'P32944': 6,\n",
       "  'P33306': 19,\n",
       "  'P33332': 0,\n",
       "  'P34161': 19,\n",
       "  'P34233': 19,\n",
       "  'P34241': 19,\n",
       "  'P34252': 12,\n",
       "  'P36005': 19,\n",
       "  'P36093': 11,\n",
       "  'P36094': 6,\n",
       "  'P36157': 19,\n",
       "  'P36158': 19,\n",
       "  'P36165': 19,\n",
       "  'P36166': 19,\n",
       "  'P36167': 19,\n",
       "  'P38042': 9,\n",
       "  'P38257': 0,\n",
       "  'P38261': 6,\n",
       "  'P38277': 19,\n",
       "  'P38634': 19,\n",
       "  'P38717': 19,\n",
       "  'P38721': 19,\n",
       "  'P38735': 0,\n",
       "  'P38826': 12,\n",
       "  'P38853': 6,\n",
       "  'P38854': 6,\n",
       "  'P38859': 12,\n",
       "  'P38903': 0,\n",
       "  'P38909': 10,\n",
       "  'P38928': 4,\n",
       "  'P38990': 11,\n",
       "  'P38991': 6,\n",
       "  'P39083': 0,\n",
       "  'P39520': 11,\n",
       "  'P39685': 4,\n",
       "  'P39705': 5,\n",
       "  'P39732': 0,\n",
       "  'P39734': 6,\n",
       "  'P39980': 19,\n",
       "  'P40020': 0,\n",
       "  'P40028': 19,\n",
       "  'P40038': 19,\n",
       "  'P40095': 0,\n",
       "  'P40186': 19,\n",
       "  'P40316': 19,\n",
       "  'P40340': 6,\n",
       "  'P40473': 19,\n",
       "  'P40480': 6,\n",
       "  'P40484': 19,\n",
       "  'P40489': 19,\n",
       "  'P41697': 6,\n",
       "  'P41813': 19,\n",
       "  'P41832': 6,\n",
       "  'P41834': 6,\n",
       "  'P41895': 9,\n",
       "  'P42839': 4,\n",
       "  'P42845': 19,\n",
       "  'P42943': 0,\n",
       "  'P43568': 5,\n",
       "  'P43605': 6,\n",
       "  'P43618': 6,\n",
       "  'P46675': 6,\n",
       "  'P47029': 19,\n",
       "  'P47039': 5,\n",
       "  'P47074': 19,\n",
       "  'P47104': 22,\n",
       "  'P47114': 19,\n",
       "  'P47116': 19,\n",
       "  'P47129': 0,\n",
       "  'P47136': 19,\n",
       "  'P50078': 19,\n",
       "  'P50090': 6,\n",
       "  'P50105': 10,\n",
       "  'P50275': 6,\n",
       "  'P52919': 6,\n",
       "  'P53071': 19,\n",
       "  'P53086': 7,\n",
       "  'P53129': 3,\n",
       "  'P53159': 6,\n",
       "  'P53197': 19,\n",
       "  'P53222': 24,\n",
       "  'P53551': 11,\n",
       "  'P53739': 19,\n",
       "  'P53819': 10,\n",
       "  'P53836': 19,\n",
       "  'P53894': 19,\n",
       "  'P53947': 19,\n",
       "  'P53958': 19,\n",
       "  'P54784': 12,\n",
       "  'P54786': 0,\n",
       "  'P54867': 19,\n",
       "  'Q00416': 0,\n",
       "  'Q00684': 19,\n",
       "  'Q00772': 19,\n",
       "  'Q01389': 0,\n",
       "  'Q01684': 0,\n",
       "  'Q02455': 11,\n",
       "  'Q02606': 19,\n",
       "  'Q02866': 5,\n",
       "  'Q03208': 19,\n",
       "  'Q03231': 19,\n",
       "  'Q03254': 6,\n",
       "  'Q03707': 23,\n",
       "  'Q03834': 12,\n",
       "  'Q03898': 19,\n",
       "  'Q04087': 6,\n",
       "  'Q04116': 19,\n",
       "  'Q04383': 22,\n",
       "  'Q04930': 19,\n",
       "  'Q05518': 7,\n",
       "  'Q05672': 5,\n",
       "  'Q05812': 22,\n",
       "  'Q05854': 19,\n",
       "  'Q06001': 6,\n",
       "  'Q06032': 19,\n",
       "  'Q06053': 18,\n",
       "  'Q06168': 10,\n",
       "  'Q06266': 18,\n",
       "  'Q06315': 19,\n",
       "  'Q06324': 6,\n",
       "  'Q06407': 6,\n",
       "  'Q06412': 19,\n",
       "  'Q06604': 0,\n",
       "  'Q06616': 6,\n",
       "  'Q06648': 0,\n",
       "  'Q07084': 19,\n",
       "  'Q07528': 6,\n",
       "  'Q07980': 18,\n",
       "  'Q08206': 19,\n",
       "  'Q08229': 0,\n",
       "  'Q08471': 19,\n",
       "  'Q08581': 6,\n",
       "  'Q08887': 19,\n",
       "  'Q08949': 13,\n",
       "  'Q08981': 19,\n",
       "  'Q12043': 5,\n",
       "  'Q12048': 19,\n",
       "  'Q12057': 22,\n",
       "  'Q12066': 15,\n",
       "  'Q12071': 6,\n",
       "  'Q12088': 19,\n",
       "  'Q12100': 19,\n",
       "  'Q12107': 9,\n",
       "  'Q12149': 16,\n",
       "  'Q12236': 22,\n",
       "  'Q12263': 6,\n",
       "  'Q12267': 6,\n",
       "  'Q12365': 6,\n",
       "  'Q12369': 19,\n",
       "  'Q12398': 5,\n",
       "  'Q12416': 19,\n",
       "  'Q12495': 6,\n",
       "  'Q12507': 15,\n",
       "  'Q12675': 22,\n",
       "  'Q12734': 19,\n",
       "  'P00549': 7,\n",
       "  'P06244': 19,\n",
       "  'Q12056': 7,\n",
       "  'P00560': 7,\n",
       "  'P0CE68': 7,\n",
       "  'P0CE69': 7,\n",
       "  'P21264': 7,\n",
       "  'P34162': 13,\n",
       "  'Q12415': 7,\n",
       "  'P00572': 5,\n",
       "  'P32502': 5,\n",
       "  'P00635': 13,\n",
       "  'P36173': 4,\n",
       "  'Q03630': 13,\n",
       "  'P00724': 15,\n",
       "  'P53295': 15,\n",
       "  'Q12154': 15,\n",
       "  'P00729': 23,\n",
       "  'P14306': 23,\n",
       "  'P25694': 23,\n",
       "  'P32915': 4,\n",
       "  'P38307': 23,\n",
       "  'Q05787': 23,\n",
       "  'Q08109': 23,\n",
       "  'P00812': 5,\n",
       "  'P43580': 5,\n",
       "  'P53281': 0,\n",
       "  'Q06142': 5,\n",
       "  'P00815': 28,\n",
       "  'P53233': 28,\n",
       "  'P00817': 17,\n",
       "  'P06787': 17,\n",
       "  'Q08409': 17,\n",
       "  'P00830': 15,\n",
       "  'P00854': 15,\n",
       "  'P00856': 15,\n",
       "  'P05626': 15,\n",
       "  'P07251': 15,\n",
       "  'P09457': 15,\n",
       "  'P21306': 15,\n",
       "  'P30902': 6,\n",
       "  'P32453': 4,\n",
       "  'P38077': 15,\n",
       "  'P38347': 15,\n",
       "  'P40892': 5,\n",
       "  'P81450': 15,\n",
       "  'Q06208': 15,\n",
       "  'Q06405': 17,\n",
       "  'Q12165': 15,\n",
       "  'P25611': 7,\n",
       "  'P00890': 13,\n",
       "  'P00899': 5,\n",
       "  'P00937': 11,\n",
       "  'P38328': 0,\n",
       "  'P41811': 22,\n",
       "  'P47120': 5,\n",
       "  'Q99312': 5,\n",
       "  'P00912': 3,\n",
       "  'P19146': 22,\n",
       "  'P00924': 7,\n",
       "  'P53732': 7,\n",
       "  'P00925': 17,\n",
       "  'P40498': 11,\n",
       "  'P41909': 7,\n",
       "  'Q06148': 3,\n",
       "  'Q08234': 4,\n",
       "  'Q6Q5F3': 12,\n",
       "  'P00927': 0,\n",
       "  'P10849': 0,\n",
       "  'P25651': 0,\n",
       "  'P32337': 5,\n",
       "  'P32776': 13,\n",
       "  'P35729': 28,\n",
       "  'P38340': 5,\n",
       "  'P47068': 0,\n",
       "  'P80667': 0,\n",
       "  'Q06338': 5,\n",
       "  'Q08907': 0,\n",
       "  'Q12163': 0,\n",
       "  'Q99189': 5,\n",
       "  'P00931': 7,\n",
       "  'P32645': 9,\n",
       "  'P00942': 7,\n",
       "  'P14772': 7,\n",
       "  'P00950': 7,\n",
       "  'P33334': 14,\n",
       "  'P53076': 17,\n",
       "  'P00958': 7,\n",
       "  'P46672': 7,\n",
       "  'P01094': 17,\n",
       "  'P07267': 17,\n",
       "  'P01097': 6,\n",
       "  'P12753': 6,\n",
       "  'P31376': 6,\n",
       "  'P34237': 6,\n",
       "  'P53253': 6,\n",
       "  'P53930': 6,\n",
       "  'Q06675': 24,\n",
       "  'P01098': 6,\n",
       "  'P35727': 6,\n",
       "  'P40368': 6,\n",
       "  'P41901': 6,\n",
       "  'Q04477': 6,\n",
       "  'Q07508': 6,\n",
       "  'Q12514': 6,\n",
       "  'P01119': 5,\n",
       "  'P34760': 5,\n",
       "  'P39010': 22,\n",
       "  'Q06214': 5,\n",
       "  'P01120': 22,\n",
       "  'P32572': 22,\n",
       "  'P33302': 22,\n",
       "  'P38165': 6,\n",
       "  'P43588': 23,\n",
       "  'P53049': 22,\n",
       "  'Q02895': 5,\n",
       "  'P01123': 3,\n",
       "  'P11076': 22,\n",
       "  'P20133': 3,\n",
       "  'P25385': 6,\n",
       "  'P27999': 9,\n",
       "  'P32601': 3,\n",
       "  'P32854': 3,\n",
       "  'P32864': 3,\n",
       "  'P38130': 0,\n",
       "  'P39958': 3,\n",
       "  'P40093': 3,\n",
       "  'P53039': 3,\n",
       "  'P53093': 3,\n",
       "  'P53108': 3,\n",
       "  'P53845': 3,\n",
       "  'P54783': 15,\n",
       "  'Q01590': 6,\n",
       "  'Q08484': 3,\n",
       "  'Q12270': 22,\n",
       "  'Q12383': 3,\n",
       "  'Q12527': 6,\n",
       "  'P02293': 10,\n",
       "  'P04911': 10,\n",
       "  'P38431': 17,\n",
       "  'P53874': 11,\n",
       "  'Q07457': 6,\n",
       "  'Q12373': 10,\n",
       "  'P02294': 5,\n",
       "  'P06104': 12,\n",
       "  'P0CY06': 5,\n",
       "  'P25293': 5,\n",
       "  'P02309': 10,\n",
       "  'P06701': 12,\n",
       "  'P15790': 11,\n",
       "  'P35817': 6,\n",
       "  'P36012': 10,\n",
       "  'P38074': 11,\n",
       "  'P38890': 19,\n",
       "  'P43572': 10,\n",
       "  'P53686': 10,\n",
       "  'P61830': 10,\n",
       "  'Q03330': 10,\n",
       "  'Q06205': 11,\n",
       "  'Q12161': 10,\n",
       "  'Q12341': 10,\n",
       "  'Q12692': 10,\n",
       "  'P02400': 12,\n",
       "  'P05317': 12,\n",
       "  'P05318': 12,\n",
       "  'P10622': 12,\n",
       "  'P32790': 0,\n",
       "  'P38067': 3,\n",
       "  'P02407': 11,\n",
       "  'P02557': 6,\n",
       "  'P09733': 6,\n",
       "  'P48606': 6,\n",
       "  'Q02785': 22,\n",
       "  'Q04004': 24,\n",
       "  'P04076': 5,\n",
       "  'P04802': 0,\n",
       "  'P04817': 4,\n",
       "  'P06101': 5,\n",
       "  'P07248': 7,\n",
       "  'P07263': 18,\n",
       "  'P07275': 5,\n",
       "  'P07991': 5,\n",
       "  'P0CD99': 4,\n",
       "  'P0CE00': 4,\n",
       "  'P0CE41': 4,\n",
       "  'P0CS82': 5,\n",
       "  'P0CX12': 4,\n",
       "  'P0CX13': 4,\n",
       "  'P0CX49': 13,\n",
       "  'P0CX50': 13,\n",
       "  'P14681': 5,\n",
       "  'P15365': 4,\n",
       "  'P15442': 7,\n",
       "  'P15625': 28,\n",
       "  'P15705': 5,\n",
       "  'P17536': 5,\n",
       "  'P19882': 19,\n",
       "  'P21147': 4,\n",
       "  'P22140': 4,\n",
       "  'P22203': 22,\n",
       "  'P23561': 5,\n",
       "  'P25294': 7,\n",
       "  'P25491': 5,\n",
       "  'P25584': 15,\n",
       "  'P25607': 4,\n",
       "  'P25623': 22,\n",
       "  'P25628': 6,\n",
       "  'P25638': 5,\n",
       "  'P28496': 4,\n",
       "  'P28707': 7,\n",
       "  'P29547': 7,\n",
       "  'P31381': 4,\n",
       "  'P32419': 17,\n",
       "  'P32460': 5,\n",
       "  'P32465': 22,\n",
       "  'P32468': 6,\n",
       "  'P32485': 19,\n",
       "  'P32487': 22,\n",
       "  'P32589': 7,\n",
       "  'P32621': 4,\n",
       "  'P32861': 5,\n",
       "  'P32939': 3,\n",
       "  'P33200': 0,\n",
       "  'P33296': 17,\n",
       "  'P33313': 5,\n",
       "  'P35497': 5,\n",
       "  'P36019': 3,\n",
       "  'P36023': 5,\n",
       "  'P36029': 4,\n",
       "  'P36088': 5,\n",
       "  'P36125': 0,\n",
       "  'P36137': 5,\n",
       "  'P36148': 5,\n",
       "  'P38075': 5,\n",
       "  'P38090': 0,\n",
       "  'P38270': 6,\n",
       "  'P38272': 18,\n",
       "  'P38318': 9,\n",
       "  'P38323': 10,\n",
       "  'P38349': 23,\n",
       "  'P38356': 4,\n",
       "  'P38429': 19,\n",
       "  'P38555': 3,\n",
       "  'P38637': 5,\n",
       "  'P38695': 22,\n",
       "  'P38720': 17,\n",
       "  'P38734': 7,\n",
       "  'P38768': 10,\n",
       "  'P38770': 28,\n",
       "  'P38825': 7,\n",
       "  'P38910': 5,\n",
       "  'P38962': 5,\n",
       "  'P39078': 0,\n",
       "  'P39721': 5,\n",
       "  'P39727': 4,\n",
       "  'P40073': 0,\n",
       "  'P40074': 18,\n",
       "  'P40169': 4,\n",
       "  'P40458': 13,\n",
       "  'P40475': 4,\n",
       "  'P40531': 5,\n",
       "  'P40549': 5,\n",
       "  'P40558': 19,\n",
       "  'P40586': 5,\n",
       "  'P41808': 5,\n",
       "  'P41815': 4,\n",
       "  'P41896': 9,\n",
       "  'P42836': 11,\n",
       "  'P43581': 17,\n",
       "  'P43682': 4,\n",
       "  'P46956': 4,\n",
       "  'P46970': 19,\n",
       "  'P46993': 18,\n",
       "  'P47023': 6,\n",
       "  'P47103': 5,\n",
       "  'P47111': 22,\n",
       "  'P47119': 13,\n",
       "  'P47123': 5,\n",
       "  'P47166': 6,\n",
       "  'P48837': 6,\n",
       "  'P49334': 15,\n",
       "  'P50276': 22,\n",
       "  'P50945': 15,\n",
       "  'P51534': 0,\n",
       "  'P52489': 19,\n",
       "  'P53043': 7,\n",
       "  'P53048': 4,\n",
       "  'P53344': 4,\n",
       "  'P53394': 4,\n",
       "  'P53629': 4,\n",
       "  'P53631': 14,\n",
       "  'P53691': 7,\n",
       "  'P53834': 7,\n",
       "  'P53918': 4,\n",
       "  'P53927': 11,\n",
       "  'P53943': 5,\n",
       "  'P89113': 10,\n",
       "  'Q02196': 5,\n",
       "  'Q02784': 0,\n",
       "  'Q02981': 5,\n",
       "  'Q03102': 5,\n",
       "  'Q03175': 7,\n",
       "  'Q03795': 17,\n",
       "  'Q03818': 5,\n",
       "  'Q04031': 6,\n",
       "  'Q04344': 5,\n",
       "  'Q04658': 5,\n",
       "  'Q05637': 19,\n",
       "  'Q05871': 5,\n",
       "  'Q06058': 19,\n",
       "  'Q06108': 5,\n",
       "  'Q06494': 5,\n",
       "  'Q06497': 4,\n",
       "  'Q06523': 10,\n",
       "  'Q06676': 7,\n",
       "  'Q06892': 5,\n",
       "  'Q07748': 17,\n",
       "  'Q07786': 5,\n",
       "  'Q07788': 5,\n",
       "  'Q07986': 13,\n",
       "  'Q07993': 5,\n",
       "  'Q08144': 4,\n",
       "  'Q08176': 7,\n",
       "  'Q08227': 4,\n",
       "  'Q08280': 22,\n",
       "  'Q08446': 19,\n",
       "  'Q08926': 15,\n",
       "  'Q08954': 5,\n",
       "  'Q08974': 10,\n",
       "  'Q08980': 4,\n",
       "  'Q12122': 17,\n",
       "  'Q12206': 5,\n",
       "  'Q12274': 15,\n",
       "  'Q12301': 5,\n",
       "  'Q12329': 15,\n",
       "  'Q12407': 4,\n",
       "  'Q12461': 0,\n",
       "  'Q12462': 15,\n",
       "  'Q12489': 0,\n",
       "  'Q12498': 5,\n",
       "  'Q12516': 5,\n",
       "  'Q99190': 4,\n",
       "  'Q99288': 5,\n",
       "  'Q99393': 15,\n",
       "  'P02992': 24,\n",
       "  'Q03050': 24,\n",
       "  'P02994': 7,\n",
       "  'P06782': 0,\n",
       "  'P16521': 7,\n",
       "  'P32471': 7,\n",
       "  'P32581': 0,\n",
       "  'P07834': 19,\n",
       "  'P17157': 19,\n",
       "  'P19659': 13,\n",
       "  'P22082': 10,\n",
       "  'P38207': 12,\n",
       "  'P38811': 10,\n",
       "  'P39013': 6,\n",
       "  'Q02336': 10,\n",
       "  'Q03081': 0,\n",
       "  'Q12377': 23,\n",
       "  'P03870': 29,\n",
       "  'P03879': 30,\n",
       "  'P11325': 30,\n",
       "  'P26637': 30,\n",
       "  'P03882': 31,\n",
       "  'P03962': 32,\n",
       "  'P04037': 16,\n",
       "  'P21954': 16,\n",
       "  'P32796': 15,\n",
       "  'P38274': 0,\n",
       "  'Q02793': 16,\n",
       "  'P43592': 6,\n",
       "  'P04046': 15,\n",
       "  'P07286': 4,\n",
       "  'P06242': 13,\n",
       "  'P07273': 9,\n",
       "  'P08518': 9,\n",
       "  'P16370': 9,\n",
       "  'P20433': 9,\n",
       "  'P20434': 9,\n",
       "  'P20435': 9,\n",
       "  'P20436': 9,\n",
       "  'P22139': 9,\n",
       "  'P23293': 11,\n",
       "  'P23615': 9,\n",
       "  'P27692': 11,\n",
       "  'P32585': 13,\n",
       "  'P34087': 9,\n",
       "  'P36145': 13,\n",
       "  'P38782': 13,\n",
       "  'P38902': 9,\n",
       "  'P39073': 13,\n",
       "  'P39081': 24,\n",
       "  'P40084': 9,\n",
       "  'P53064': 11,\n",
       "  'P53538': 24,\n",
       "  'P53617': 9,\n",
       "  'P53842': 9,\n",
       "  'Q01477': 9,\n",
       "  'Q03957': 17,\n",
       "  'Q05543': 6,\n",
       "  'Q06632': 24,\n",
       "  'Q06697': 11,\n",
       "  'Q06706': 9,\n",
       "  'Q06834': 9,\n",
       "  'P04051': 9,\n",
       "  'P07703': 9,\n",
       "  'P15891': 0,\n",
       "  'P22276': 9,\n",
       "  'P32349': 9,\n",
       "  'P32910': 9,\n",
       "  'P35718': 9,\n",
       "  'P41910': 19,\n",
       "  'P04147': 14,\n",
       "  'P05453': 0,\n",
       "  'P07260': 14,\n",
       "  'P30822': 14,\n",
       "  'P36102': 14,\n",
       "  'P39935': 14,\n",
       "  'P39936': 14,\n",
       "  'P40561': 14,\n",
       "  'P53297': 14,\n",
       "  'Q99257': 5,\n",
       "  'P04161': 13,\n",
       "  'P25337': 13,\n",
       "  'P36108': 24,\n",
       "  'Q12343': 13,\n",
       "  'P04173': 19,\n",
       "  'P04385': 13,\n",
       "  'P04387': 13,\n",
       "  'P04386': 13,\n",
       "  'P13393': 10,\n",
       "  'P53549': 23,\n",
       "  'Q02516': 0,\n",
       "  'P07269': 0,\n",
       "  'P13045': 3,\n",
       "  'P25046': 13,\n",
       "  'P25367': 5,\n",
       "  'P25502': 9,\n",
       "  'P32607': 13,\n",
       "  'P33308': 13,\n",
       "  'P36000': 24,\n",
       "  'P36003': 3,\n",
       "  'P38709': 13,\n",
       "  'P39959': 13,\n",
       "  'P40959': 17,\n",
       "  'P41913': 0,\n",
       "  'P47822': 13,\n",
       "  'P48235': 24,\n",
       "  'P50102': 10,\n",
       "  'P50875': 10,\n",
       "  'Q00723': 14,\n",
       "  'Q03067': 10,\n",
       "  'Q05610': 23,\n",
       "  'Q05785': 6,\n",
       "  'Q08601': 13,\n",
       "  'Q08831': 13,\n",
       "  'Q12493': 6,\n",
       "  'P04397': 24,\n",
       "  'P38700': 24,\n",
       "  'Q08293': 19,\n",
       "  'P04449': 11,\n",
       "  'P0CX41': 11,\n",
       "  'Q12522': 11,\n",
       "  'P04456': 7,\n",
       "  'Q02642': 7,\n",
       "  'P04650': 5,\n",
       "  'P38615': 5,\n",
       "  'P04710': 14,\n",
       "  'P47017': 14,\n",
       "  'P53744': 14,\n",
       "  'Q07807': 14,\n",
       "  'P04786': 6,\n",
       "  'P0CY08': 28,\n",
       "  'P0CY12': 28,\n",
       "  'P21651': 6,\n",
       "  'P32489': 6,\n",
       "  'P50946': 24,\n",
       "  'Q05024': 7,\n",
       "  'Q12255': 6,\n",
       "  'P04801': 13,\n",
       "  'P38781': 15,\n",
       "  'Q08741': 0,\n",
       "  'P04803': 15,\n",
       "  'Q12420': 15,\n",
       "  'P04806': 14,\n",
       "  'P40434': 14,\n",
       "  'Q3E7X8': 14,\n",
       "  'P04807': 14,\n",
       "  'P27705': 0,\n",
       "  'P14906': 4,\n",
       "  'P16661': 4,\n",
       "  ...}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate dendrogram\n",
    "dendroG = community_louvain.generate_dendrogram(G, part_init = partition)# , part_init = partition\n",
    "dendroG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in range(len(dendroG) - 1) :\n",
    "    if level != 0:\n",
    "        print(\"partition at level\", level,\n",
    "        \"is\", community_louvain.partition_at_level(dendroG, level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.578502624558621"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_louvain.modularity(partition, G) # modularity: 0.576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korkin said they found 81 communities\n",
    "# How do we determine the number of communities discovered by Louvain Algo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x269af2785c8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = community_louvain.induced_graph(partition, G)\n",
    "g\n",
    "#dendroG = community_louvain.generate_dendrogram(g, part_init = partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition = community_louvain.best_partition(g)\n",
    "partition.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x269af27bf48>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dev, keeping for notes but replaceing with version from git as this is not running as expected. \n",
    "class RobustL21Autoencoder():\n",
    "    \"\"\"\n",
    "    @author: Chong Zhou\n",
    "    first version.\n",
    "    complete: 10/20/2016\n",
    "    Update to Python3: 03/15/2019\n",
    "    Des:\n",
    "        X = L + S\n",
    "        L is a non-linearly low dimension matrix and S is a sparse matrix.\n",
    "        argmin ||L - Decoder(Encoder(L))|| + ||S||_2,1\n",
    "        Use Alternating projection to train model\n",
    "        The idea of shrink the l21 norm comes from the wiki 'Regularization' link: {\n",
    "            https://en.wikipedia.org/wiki/Regularization_(mathematics)\n",
    "        }\n",
    "    Improve:\n",
    "        1. fix the 0-cost bugs\n",
    "    \"\"\"\n",
    "    # take self and it's parameters to initialize a deep autoencoder with session, input dim list, and self layers sizes\n",
    "    def __init__(self, sess, layers_sizes, lambda_=1.0, error = 1.0e-5):\n",
    "        self.lambda_ = lambda_\n",
    "        self.layers_sizes = layers_sizes\n",
    "        self.error = error\n",
    "        self.errors=[]\n",
    "        self.AE = DAE.Deep_Autoencoder(sess = sess, input_dim_list = self.layers_sizes)\n",
    "\n",
    "    # take the initialized NN and input matrix X (as well as LR, inner iter, iter, batch size, and verbose params)\n",
    "    def fit(self, X, sess, learning_rate=0.15, inner_iteration = 50,\n",
    "            iteration= 3, batch_size=6, verbose=True):\n",
    "        # iters = 20, batch size: 40\n",
    "        \n",
    "        ## The first layer must be the input layer, so they should have same sizes.\n",
    "        assert X.shape[1] == self.layers_sizes[0]\n",
    "        \n",
    "        ## initialize L, S, as empty vectors\n",
    "        ## and mu(shrinkage operator)??? initialized mu? \n",
    "        self.L = np.zeros(X.shape)\n",
    "        self.S = np.zeros(X.shape)\n",
    "         \n",
    "        ## To estimate the size of input X\n",
    "        if verbose:\n",
    "            print (\"X shape: \", X.shape)\n",
    "            print (\"L shape: \", self.L.shape)\n",
    "            print (\"S shape: \", self.S.shape)\n",
    "            \n",
    "        # For each (outer) iteration, print out the iteration number\n",
    "        for it in range(iteration):\n",
    "            if verbose:\n",
    "                print (\"Out iteration: \" , it)\n",
    "            \n",
    "            ## alternating project, first project to L\n",
    "            self.L = X - self.S\n",
    "            \n",
    "            ## Using L to train the auto-encoder\n",
    "            self.AE.fit(self.L, sess = sess,\n",
    "                                    iteration = inner_iteration,\n",
    "                                    learning_rate = learning_rate,\n",
    "                                    batch_size = batch_size,\n",
    "                                    verbose = verbose)\n",
    "            ## get optmized L\n",
    "            ## what's this doing? ...\n",
    "            self.L = self.AE.getRecon(X = self.L, sess = sess)\n",
    "            \n",
    "            ## alternating project, now project to S and shrink S\n",
    "            #self.S = SHR.l21shrink(self.lambda_, (X - self.L)) # changed from l21 to l1\n",
    "            # what is the shrink function doing\n",
    "            \n",
    "            # take self.shrink, X-L, reshaped.... \n",
    "            # shrink (below) takes x and shrinkage parameter epsilon (a scalar or vector) and returns a shrunk vector\n",
    "            # so in this case, the input is self.shrink, and 'X' is actually 'S' (because X - L is S)\n",
    "            # reshape is a numpy function that takes as arguments 'a' - an array to be reshaped, newshape, and order = 'C'\n",
    "            ## C means to read / write the elements using C-like index order, with the last axis index changing fastest, \n",
    "            ## back to the first axis index changing slowest.\n",
    "            ### so S is reshaped to X.size, fed to the shrink function, and the shrunk vector is reshaped to X.shape\n",
    "            ### so clearly the reshape is to allow for the flow of the x vactor amongst these functions, but isn't \n",
    "            ### the x-vector shape/size the same? Let's check it out\n",
    "            print(\"X size:\", X.size)\n",
    "            print(\"X shape:\", X.shape)\n",
    "            self.S = RobustL21Autoencoder.shrink(shrink, (self.X - self.L).reshape(X.size,order='C')).reshape(X.shape,order='C')\n",
    "            \n",
    "        return self.L , self.S\n",
    "    \n",
    "    def transform(self, X, sess):\n",
    "        L = X - self.S\n",
    "        return self.AE.transform(X = L, sess = sess)\n",
    "    def getRecon(self, X, sess):\n",
    "        return self.AE.getRecon(X, sess = sess)\n",
    "    \n",
    "    def shrink(epsilon, x):\n",
    "        \"\"\"\n",
    "        @Original Author: Prof. Randy\n",
    "        @Modified by: Chong Zhou\n",
    "        Args:\n",
    "            epsilon: the shrinkage parameter (either a scalar or a vector)\n",
    "            x: the vector to shrink on\n",
    "        Returns:\n",
    "            The shrunk vector\n",
    "        \"\"\"\n",
    "        output = np.array(x*0.)\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            if x[i] > epsilon:\n",
    "                output[i] = x[i] - epsilon\n",
    "            elif x[i] < -epsilon:\n",
    "                output[i] = x[i] + epsilon\n",
    "            else:\n",
    "                output[i] = 0\n",
    "        return output\n",
    "\n",
    "    \n",
    "# Model my code below after this section:    \n",
    "#if __name__ == \"__main__\":\n",
    "#    x = np.load(r\"../data/data.npk\", allow_pickle = True)[:500]\n",
    "#    \n",
    "#    with tf.Session() as sess:\n",
    "#        rae = RobustL21Autoencoder(sess = sess, lambda_= 4000, layers_sizes=[784,400,255,100]) # [784,400,255,100]\n",
    "\n",
    "#        L, S = rae.fit(x, sess = sess, inner_iteration = 60, iteration = 5,verbose = True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
